{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bf3fd108-3de9-46f7-96f2-de21d420b750",
      "metadata": {
        "id": "bf3fd108-3de9-46f7-96f2-de21d420b750"
      },
      "source": [
        "# 🧠🧠🌾🌾Crop Export Value MLP Project\n",
        "\n",
        "This project aims to build a multilayer perceptron model that can be used for forecasting the export value of crop products for a geographical region three years into the future (e.g. given historical data up until or at Year 2984, the model should be able to predict the export value of crop products for Year 2987). The model can be either a regression model or a classification model.\n",
        "\n",
        "## Project Data Description\n",
        "\n",
        "The dataset used for this project is made up of data extracted from the [FAOSTAT database](https://www.fao.org/faostat/en/#home), which gives open access to food and agricultural data for over 245 countries and covers years from mid 1990s to present day.\n",
        "\n",
        "The project Dataset contains 13 csv files, each covering a category of variables relevant to food and agriculture. Here are the 13 categories covered (with the corresponding FAOSTAT source for each category);\n",
        "\n",
        "- Consumer prices indicators - [link](https://www.fao.org/faostat/en/%23ata/CP)\n",
        "- Crops production indicators - [link](https://www.fao.org/faostat/en/%23data/QCL)\n",
        "- Emissions - [link1](https://www.fao.org/faostat/en/%23data/GCE) and [link2](https://www.fao.org/faostat/en/%23data/GV)\n",
        "- Employment - [link](https://www.fao.org/faostat/en/%23data/OEA)\n",
        "- Exchange rate -  [link](https://www.fao.org/faostat/en/%23data/PE)\n",
        "- Fertilizers use - [link](https://www.fao.org/faostat/en/%23data/RFB)\n",
        "- Food balances indicators - [link](https://www.fao.org/faostat/en/%23data/FBS)\n",
        "- Food security indicators - [link](https://www.fao.org/faostat/en/%23data/FS)\n",
        "- Food trade indicators - [link](https://www.fao.org/faostat/en/%23data/TCL)\n",
        "- Foreign direct investment - [link](https://www.fao.org/faostat/en/%23data/FDI)\n",
        "- Land temperature change - [link](https://www.fao.org/faostat/en/#%23ata/ET)\n",
        "- Land use - [link](https://www.fao.org/faostat/en/#%23ata/RL)\n",
        "- Pesticides use - [link](https://www.fao.org/faostat/en/%23data/RP)\n",
        "\n",
        "You can see [here](https://www.fao.org/faostat/en/%23definitions) for more details about the headers in the data files. The table below provides a summary of the variables included in each file.\n",
        "\n",
        "\n",
        "## Consumer price indicators\n",
        "- Consumer price, food index\n",
        "- Country\n",
        "- Food price inflation\n",
        "-  Month\n",
        "- Year\n",
        "  \n",
        "## Crops production indicators\n",
        "- Country\n",
        "- Year\n",
        "- Yield for different crop products\n",
        "\n",
        "\n",
        "## Emissions\n",
        "- Country\n",
        "- Crops CH4 emissions\n",
        "- Crops N2O emissions\n",
        "- Drained soil CO2 emissions\n",
        "- Drained soil N2O emissions\n",
        "- Year\n",
        "\n",
        "## Employment\n",
        "- Country\n",
        "- Employment (male and female total) in agriculture, forestry, and fishing\n",
        "- Mean weekly hours worked per person (no distinction between male and female) in agriculture, forestry, and fishing\n",
        "- Year\n",
        "  \n",
        "## Exchange rate\n",
        "- Country\n",
        "- Currency\n",
        "- Local currency units per USD\n",
        "- Months\n",
        "- Year\n",
        "  \n",
        "## Fertilizers use\n",
        "- Agricultural use of different categories of fertilizers\n",
        "- Country\n",
        "- Year\n",
        "\n",
        "## Food balances\n",
        "- Country\n",
        "- Export quantity for different crop and livestock products\n",
        "- Food uses for different crop and livestock products\n",
        "- Import quantity for different crop and livestock products\n",
        "- Losses for crop and livestock products\n",
        "- Other uses for crop and livestock products\n",
        "- Year\n",
        "\n",
        "## Food security\n",
        "- Cereal import dependency ratio\n",
        "- Country\n",
        "- Dietary energy supply adequacy\n",
        "- Per capita food production variability\n",
        "- Per capita food supply variability\n",
        "- Percentage of arable land equipped for irrigation\n",
        "- Political stability and absence of violence/terrorism index\n",
        "- Prevalence of anaemia in women of reproductive age\n",
        "- Prevalence of low birthweight\n",
        "- Protein energy supply\n",
        "- Value of food imports in total merchandise exports\n",
        "- Year\n",
        "  \n",
        "## Food trade\n",
        "- Country\n",
        "- Export value\n",
        "- Import value\n",
        "- Year\n",
        "\n",
        "## Foreign direct investment (FDI)\n",
        "- Country\n",
        "- FDI inflows to agriculture, forestry, and fishing\n",
        "- FDI inflows to food, beverages, and tobacco\n",
        "- FDI outflows to agriculture, forestry, and fishing\n",
        "- FDI outflows to food, beverages, and tobacco\n",
        "- Total FDI inflows\n",
        "- Total FDI outflows\n",
        "- Year\n",
        "  \n",
        "## Land temperature change\n",
        "- Country\n",
        "- Months\n",
        "- Temperature change\n",
        "- Standard deviation\n",
        "- Year\n",
        "\n",
        "  \n",
        "## Land use\n",
        "- Area for different categories of land use\n",
        "- Country\n",
        "- Year\n",
        "  \n",
        "## Pesticides use\n",
        "- Agricultural use for each of fungicides (and bactericides), herbicides, insecticides, pesticides, rodenticides\n",
        "- Country\n",
        "- Use per area of cropland for each of fungicides (and bactericides), herbicides, insecticides, pesticides, rodenticides\n",
        "- Use per value of agricultural production for each of fungicides (and bactericides), herbicides, insecticides, pesticides, rodenticides\n",
        "- Year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0d35575-5134-4a7c-a7b5-8d092d34096c",
      "metadata": {
        "id": "c0d35575-5134-4a7c-a7b5-8d092d34096c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "62d0ac94-5f49-4406-c4f2-9993144519c7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Crowntech\\\\Documents\\\\Projects\\\\Mlp project\\\\Consumer prices indicators - FAOSTAT_data_en_2-22-2024.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2b0a7bc25df0>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the CSV files into pandas DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mconsumer_pi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Consumer prices indicators - FAOSTAT_data_en_2-22-2024.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcrop_pi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Crops production indicators - FAOSTAT_data_en_2-22-2024.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfood_trade_indicators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Food trade indicators - FAOSTAT_data_en_2-22-2024.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Crowntech\\\\Documents\\\\Projects\\\\Mlp project\\\\Consumer prices indicators - FAOSTAT_data_en_2-22-2024.csv'"
          ]
        }
      ],
      "source": [
        "# Necessary imports\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV files into pandas DataFrames\n",
        "consumer_pi = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Consumer prices indicators - FAOSTAT_data_en_2-22-2024.csv')\n",
        "crop_pi = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Crops production indicators - FAOSTAT_data_en_2-22-2024.csv')\n",
        "food_trade_indicators = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Food trade indicators - FAOSTAT_data_en_2-22-2024.csv')\n",
        "food_balances_indicators = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Food balances indicators - FAOSTAT_data_en_2-22-2024.csv')\n",
        "emissions = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Emissions - FAOSTAT_data_en_2-27-2024.csv')\n",
        "employment = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Employment - FAOSTAT_data_en_2-27-2024.csv')\n",
        "exchange_rates = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Exchange rate - FAOSTAT_data_en_2-22-2024.csv')\n",
        "fertilizers_used = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Fertilizers use - FAOSTAT_data_en_2-27-2024.csv')\n",
        "pesticides = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Pesticides use - FAOSTAT_data_en_2-27-2024.csv')\n",
        "land_use = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Land use - FAOSTAT_data_en_2-22-2024.csv')\n",
        "fdi = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Foreign direct investment - FAOSTAT_data_en_2-27-2024.csv')\n",
        "fsi = fdi = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Food security indicators  - FAOSTAT_data_en_2-22-2024.csv')\n",
        "land_temp_change = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Land temperature change - FAOSTAT_data_en_2-27-2024.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f3e567a-a21d-4151-874e-e0e6b848ae14",
      "metadata": {
        "id": "1f3e567a-a21d-4151-874e-e0e6b848ae14"
      },
      "source": [
        "### `consumer_price_indicators` data preparation\n",
        "\n",
        "These are the steps done on the consumer_price_indicators dataset.\n",
        "\n",
        "`Note:` `consumer_pi` = `consumer_price_indicators`\n",
        "\n",
        "- Drop the `Domain Code` and `Domain` columns.\n",
        "- Use the `Item` column to split the data into 2 different datasets.\n",
        "     - `Consumer Price, Food indices (2015=100)`\n",
        "     - `Food price inflation`\n",
        "- Drop the `Item Code` column.\n",
        "- Drop the `Element Code` and `Element` columns.\n",
        "- Drop the `Unit` column.\n",
        "- Drop the `Flag` and `Flag Description` columns.\n",
        "- Drop the `Note` column.\n",
        "\n",
        "- For each of these datasets drop the `Item` column and change the `Values` column into;\n",
        "    - `Consumer Price for the Year`\n",
        "    - `Avg Food price inflation(%) for the Year`\n",
        "- For the `Months` column, aggregate the values by finding the total of all the months for each year for the `Consumer Price for the Year` and aggregate by average for the `Food price inflation(%) for the Year`. Drop the `Months` column after aggregating.\n",
        "  \n",
        "- merge the datasets back on common columns i.e (`Area Code`, `Area`, `Year Code`, `Year`)\n",
        "\n",
        "- To get the final `consumer_pr` dataset with columns (`Area Code`, `Area`, `Year Code`, `Year`, `Consumer Price for the Year`, `Avg Food price inflation for the Year`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a319d55c-d237-4b47-97ab-fb457181df64",
      "metadata": {
        "id": "a319d55c-d237-4b47-97ab-fb457181df64",
        "outputId": "202b4c3f-f6dd-4429-fb68-5475525bfd3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'consumer_pi' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9ad1181941ff>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconsumer_pi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'consumer_pi' is not defined"
          ]
        }
      ],
      "source": [
        "consumer_pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3712a1c9-8088-4443-9d9d-5566f0387ae7",
      "metadata": {
        "id": "3712a1c9-8088-4443-9d9d-5566f0387ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "98c32f1d-fe8c-42dc-f016-5a2c63d64344"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'consumer_pi' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5c577aad5e64>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Drop redundant columns from the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcolumns_to_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Domain Code'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Domain'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Item Code'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Element Code'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Element'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Flag Description'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Note'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Area Code (M49)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Year Code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconsumer_pi_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsumer_pi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_to_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Split the DataFrame based on 'Item' values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'consumer_pi' is not defined"
          ]
        }
      ],
      "source": [
        "# Drop redundant columns from the dataframe\n",
        "columns_to_drop = ['Domain Code', 'Domain', 'Item Code', 'Element Code', 'Element', 'Unit', 'Flag', 'Flag Description', 'Note', 'Area Code (M49)', 'Year Code']\n",
        "consumer_pi_cleaned = consumer_pi.drop(columns=columns_to_drop)\n",
        "\n",
        "# Split the DataFrame based on 'Item' values\n",
        "consumer_price = consumer_pi_cleaned[consumer_pi_cleaned['Item'] == 'Consumer Prices, Food Indices (2015 = 100)']\n",
        "food_price = consumer_pi_cleaned[consumer_pi_cleaned['Item'] == 'Food price inflation']\n",
        "\n",
        "# Drop 'Item' column and rename 'Values' column\n",
        "consumer_price = consumer_price.drop(columns='Item')\n",
        "consumer_price.rename(columns={'Value': 'Total Consumer Price ($) for the Year'}, inplace=True)\n",
        "\n",
        "food_price = food_price.drop(columns='Item')\n",
        "food_price.rename(columns={'Value': 'Avg Food price inflation(%) for the Year'}, inplace=True)\n",
        "\n",
        "# Aggregate 'Months' column by sum for Consumer Price and by mean for Food Price\n",
        "consumer_price_grouped = consumer_price.groupby(['Area', 'Year']).agg({'Total Consumer Price ($) for the Year': 'sum'}).reset_index()\n",
        "food_price_grouped = food_price.groupby(['Area', 'Year']).agg({'Avg Food price inflation(%) for the Year': 'mean'}).reset_index()\n",
        "\n",
        "# Merge datasets back on common columns\n",
        "cleaned_consumer_pi = pd.merge(consumer_price_grouped, food_price_grouped,\n",
        "                               on=['Area', 'Year'])\n",
        "\n",
        "# Export the cleaned_consumer_pi DataFrame to CSV\n",
        "cleaned_consumer_pi.to_csv('cleaned_consumer_pi.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06337be5-1e5e-449a-809f-5e324542dbe4",
      "metadata": {
        "id": "06337be5-1e5e-449a-809f-5e324542dbe4"
      },
      "source": [
        "### `crop_production_indicators` data preparation\n",
        "\n",
        "Note: `crop_pi` = `crop_production_indicators`\n",
        "\n",
        "- Drop the `Domain Code` and `Domain` columns.\n",
        "- Drop the `Item Code (CPC)` column.\n",
        "- Drop the `Element Code` and `Element` columns.\n",
        "- Drop the `Unit` column.\n",
        "- Drop the `Flag` and `Flag Description` columns.\n",
        "- Use the `Item` column to split the data into 11 different datasets.\n",
        "    - `Cereals, primary`\n",
        "    - `Citrus fruit, Total`\n",
        "    - `Fibre crops, Fibre Equivalent`\n",
        "    - `Fruit, Primary`\n",
        "    - `Oil crops, Cake Equivalent`\n",
        "    - `Oil crops, Oil Equivalent`\n",
        "    - `Pulses, Total`\n",
        "    - `Roots and Tubers, Total`\n",
        "    - `Sugar Crops Primary`\n",
        "    - `Treenuts, Total`\n",
        "    - `Vegetables, Primary`\n",
        "- For each of these datasets drop the `Item` column and change the `Values` column into;\n",
        "    - `Yearly Yield for Cereals, primary`\n",
        "    - `Yearly Yield for Citrus fruit, Total`\n",
        "    - `Yearly Yield for Fibre crops, Fibre Equivalent`\n",
        "    - `Yearly Yield for Fruit, Primary`\n",
        "    - `Yearly Yield for Oil crops, Cake Equivalent`\n",
        "    - `Yearly Yield for Oil crops, Oil Equivalent`\n",
        "    - `Yearly Yield for Pulses, Total`\n",
        "    - `Yearly Yield for Roots and Tubers, Total`\n",
        "    - `Yearly Yield for Sugar Crops Primary`\n",
        "    - `Yearly Yield for Treenuts, Total`\n",
        "    - `Yearly Yield for Vegetables, Primary`\n",
        "  \n",
        "- Merge the datasets back on common columns i.e (`Area Code`, `Area`, `Year Code`, `Year`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1921d25e-121c-453d-a6ba-a792f985d40d",
      "metadata": {
        "id": "1921d25e-121c-453d-a6ba-a792f985d40d"
      },
      "outputs": [],
      "source": [
        "crop_pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f81cf02b-b53c-4324-a3ea-3f2eeec93710",
      "metadata": {
        "id": "f81cf02b-b53c-4324-a3ea-3f2eeec93710"
      },
      "outputs": [],
      "source": [
        "crop_pi = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Crops production indicators - FAOSTAT_data_en_2-22-2024.csv')\n",
        "\n",
        "# Multiply all values in the 'Value' column by 100 since unit is (100g/hectare)\n",
        "crop_pi['Value'] *= 100\n",
        "\n",
        "# Divide all values in the 'Value' column by 1,000,000 to convert to (tonne/hectare)\n",
        "crop_pi['Value'] /= 1000000\n",
        "\n",
        "# Drop redundant columns\n",
        "columns_to_drop = ['Domain Code', 'Domain', 'Item Code (CPC)', 'Element Code', 'Element', 'Unit', 'Flag', 'Flag Description', 'Area Code (M49)', 'Year Code']\n",
        "crop_pi_cleaned = crop_pi.drop(columns=columns_to_drop)\n",
        "\n",
        "# Split the DataFrame based on unique 'Item' values\n",
        "items = crop_pi_cleaned['Item'].unique()\n",
        "\n",
        "# Create a dataframes dictionary that holds each of the split dataframes as key value pairs.\n",
        "dataframes = {}\n",
        "for item in items:\n",
        "    item_df = crop_pi_cleaned[crop_pi_cleaned['Item'] == item]\n",
        "    # Replace all punctuations to form the item names\n",
        "    item_name = item.lower().replace(', ', '_').replace(' ', '_').replace('-', '_').replace('.', '') + \" (tonne/hectare)\"\n",
        "    # Append each dataframe name and its corresponding values to our empty dictionary.\n",
        "    dataframes[item_name] = item_df\n",
        "\n",
        "# Export each dataframe to CSV and perform column renaming\n",
        "for df_name, df in dataframes.items():\n",
        "    df.drop(columns='Item', inplace=True)\n",
        "    df.rename(columns={'Value': f'Yearly Yield for {df_name.replace(\"_\", \" \").title()}'}, inplace=True)\n",
        "    # df.to_csv(f'{df_name}.csv', index=False)\n",
        "\n",
        "# Merge all dataframes back on common columns\n",
        "common_columns = ['Area', 'Year']\n",
        "cleaned_crop_pi = pd.concat(dataframes.values()).groupby(common_columns).sum().reset_index()\n",
        "\n",
        "# Export the cleaned_crop_pi DataFrame to CSV\n",
        "cleaned_crop_pi.to_csv('cleaned_crop_pi.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9af81136-b0c0-4c43-beb2-6bc90f30c60a",
      "metadata": {
        "id": "9af81136-b0c0-4c43-beb2-6bc90f30c60a"
      },
      "source": [
        "### `Emissons` data preparation\n",
        "\n",
        "- Split data into two `Emissions from crops` and `Emissions from drained organic soils`.\n",
        "\n",
        "#### `crop_emissions` data preparation\n",
        "\n",
        "- Drop the `Domain` and `Domain Code` columns.\n",
        "- Use the `Element` column to split into two, `crop_ch4_emissions` and `crop_n2o_emissions`.\n",
        "\n",
        "##### `crop_ch4_emissions` data preparation\n",
        "\n",
        "- Drop the `Domain` and `Domain Code` columns.\n",
        "- Drop the `Element` and `Element Code` columns.\n",
        "- Drop the `Item` and `Item code` columns.\n",
        "- Drop the `Source` and `Source Code` columns.\n",
        "- Change the `Value` column to `Crop ch4 emissions (Tonnes) for the year` and multiply all values by 1000.\n",
        "- Drop the `Unit` column.\n",
        "- Drop the `Flag Description` and `Note` column.\n",
        "\n",
        "- Remaining - `Area Code`, `Area`, `Year Code`, `Year`, `Crop ch4 emissions (Tonnes) for the Year`\n",
        "\n",
        "##### `crop_n20_emissions` data preparation\n",
        "\n",
        "- Drop the `Domain` and `Domain Code` columns.\n",
        "- Drop the `Element` and `Element Code` columns.\n",
        "- Drop the `Item` and `Item code` columns.\n",
        "- Drop the `Source` and `Source Code` columns.\n",
        "- Change the `Value` column to `Crop n2o emissions (Tonnes) for the year` and multiply all values by 1000.\n",
        "- Drop the `Unit` column.\n",
        "- Drop the `Flag Description` and `Note` column.\n",
        "\n",
        "- Remaining - `Area Code`, `Area`, `Year Code`, `Year`, `Crop n2o emissions (Tonnes) for the Year`\n",
        "\n",
        "#### `crop_emissions` data preparation complete\n",
        "\n",
        "- merge the `crop_ch4_emissions` and `crop_n2o_emissions` data together on common columns i.e (`Area Code`, `Area`, `Year Code`, `Year`)\n",
        "\n",
        "- Remaining - `Area Code`, `Area`, `Year Code`, `Year`, `Crop n2o emissions (Tonnes) for the Year`, `Crop ch4 emissions (Tonnes) for the Year`\n",
        "\n",
        "#### `organic_emissions` data preparation\n",
        "\n",
        "- Drop the `Domain Code` and `Domain` columns.\n",
        "- Split into two `co2_organic_emissions` and second `n2o_organic_emissions`\n",
        "\n",
        "##### `co2_organic_emissions` data preparation\n",
        "\n",
        "- Drop the `Domain` and `Domain Code` columns.\n",
        "- Drop the `Element` and `Element Code` columns.\n",
        "- Drop the `Item` and `Item code` columns.\n",
        "- Drop the `Source` and `Source Code` columns.\n",
        "- Change the `Value` column to `Organic co2 emissions (Tonnes) for the year` and multiply all values by 1000.\n",
        "- Drop the `Unit` column.\n",
        "- Drop the `Flag Description` and `Note` column.\n",
        "\n",
        "- Remaining - `Area Code`, `Area`, `Year Code`, `Year`, `Organic co2 emissions (Tonnes) for the year`\n",
        "\n",
        "##### `n2o_organic_emissions` data preparation\n",
        "\n",
        "- Drop the `Domain` and `Domain Code` columns.\n",
        "- Drop the `Element` and `Element Code` columns.\n",
        "- Drop the `Item` and `Item code` columns.\n",
        "- Drop the `Source` and `Source Code` columns.\n",
        "- Change the `Value` column to `Organic n2o emissions (Tonnes) for the year` and multiply all values by 1000.\n",
        "- Drop the `Unit` column.\n",
        "- Drop the `Flag Description` and `Note` column.\n",
        "\n",
        "- Remaining - `Area Code`, `Area`, `Year Code`, `Year`, `Organic n2o emissions (Tonnes) for the year`\n",
        "\n",
        "#### `organic_emissions` data preparation complete\n",
        "\n",
        "- merge the `ch4_organic_emissions` and `n2o_organic_emissions` data together on common columns i.e (`Area Code`, `Area`, `Year Code`, `Year`)\n",
        "\n",
        "- Remaining - `Area Code`, `Area`, `Year Code`, `Year`, `Organic n2o emissions (Tonnes) for the year`, `Organic co2 emissions (Tonnes) for the year`\n",
        "\n",
        "### `Emissions` data preparation complete\n",
        "\n",
        "- merge the `crop_emissions` and `organic_emissions` data together on common columns i.e (`Area Code`, `Area`, `Year Code`, `Year`)\n",
        "\n",
        "- Remaining - `Area Code`, `Area`, `Year Code`, `Year`, `Crop n2o emissions (Tonnes) for the Year`, `Crop ch4 emissions (Tonnes) for the Year`, `Organic n2o emissions (Tonnes) for the year`, `Organic co2 emissions (Tonnes) for the year`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aab76e12-1b5e-4165-8f54-2d27791e6d12",
      "metadata": {
        "id": "aab76e12-1b5e-4165-8f54-2d27791e6d12"
      },
      "outputs": [],
      "source": [
        "# Split the DataFrame into two diffrent dataframes based on 'Domain' values and drop redundant columns\n",
        "organic_emissions = emissions[emissions['Domain'] == 'Emissions from Drained organic soils'].drop(columns=['Domain Code', 'Domain', 'Area Code (M49)', 'Year Code'])\n",
        "crop_emissions = emissions[emissions['Domain'] == 'Emissions from Crops'].drop(columns=['Domain Code', 'Domain', 'Area Code (M49)', 'Year Code'])\n",
        "\n",
        "# Now for Crop Emissions\n",
        "# Split crop_emissions into two dataframe based on Ch4 and N2O emissions and drop redundant columns\n",
        "crop_ch4_emissions = crop_emissions[crop_emissions['Element'] == 'Crops total (Emissions CH4)'].drop(columns=['Element', 'Element Code', 'Item', 'Item Code (CPC)', 'Source', 'Source Code', 'Unit', 'Flag Description', 'Note', 'Flag'])\n",
        "crop_n2o_emissions = crop_emissions[crop_emissions['Element'] == 'Crops total (Emissions N2O)'].drop(columns=['Element', 'Element Code', 'Item', 'Item Code (CPC)', 'Source', 'Source Code', 'Unit', 'Flag Description', 'Note', 'Flag'])\n",
        "\n",
        "# Apply the `Units` column for the  crop_emissions values\n",
        "crop_ch4_emissions.rename(columns={'Value': 'Crop ch4 emissions (Tonnes) for the year'}, inplace=True)\n",
        "crop_n2o_emissions.rename(columns={'Value': 'Crop n2o emissions (Tonnes) for the year'}, inplace=True)\n",
        "crop_ch4_emissions['Crop ch4 emissions (Tonnes) for the year'] *= 1000\n",
        "crop_n2o_emissions['Crop n2o emissions (Tonnes) for the year'] *= 1000\n",
        "\n",
        "# For co2 organic emissions\n",
        "co2_organic_emissions = organic_emissions[organic_emissions['Element'] == 'Emissions (CO2)']\n",
        "\n",
        "# Split the `co2_organic_emissions` into two dataframes\n",
        "cropland_co2_organic = co2_organic_emissions[co2_organic_emissions['Item'] == 'Cropland organic soils'].drop(columns=['Element', 'Element Code', 'Item', 'Item Code (CPC)', 'Source', 'Source Code', 'Unit', 'Flag Description', 'Note', 'Flag'])\n",
        "grassland_co2_organic = co2_organic_emissions[co2_organic_emissions['Item'] == 'Grassland organic soils'].drop(columns=['Element', 'Element Code', 'Item', 'Item Code (CPC)', 'Source', 'Source Code', 'Unit', 'Flag Description', 'Note', 'Flag'])\n",
        "\n",
        "# Rename 'Items' columns for these two dataframes\n",
        "cropland_co2_organic.rename(columns={'Value': 'Cropland Organic co2 emissions (Tonnes) for the year'}, inplace=True)\n",
        "grassland_co2_organic.rename(columns={'Value': 'Grassland Organic co2 emissions (Tonnes) for the year'}, inplace=True)\n",
        "\n",
        "co2_organic_emissions = pd.merge(cropland_co2_organic, grassland_co2_organic, on=['Area', 'Year'])\n",
        "co2_organic_emissions['Cropland Organic co2 emissions (Tonnes) for the year'] *= 1000\n",
        "co2_organic_emissions['Grassland Organic co2 emissions (Tonnes) for the year'] *= 1000\n",
        "\n",
        "# For n2o organic emissions\n",
        "n2o_organic_emissions = organic_emissions[organic_emissions['Element'] == 'Emissions (N2O)']\n",
        "\n",
        "# Split the `n2o_organic_emissions` into two dataframes\n",
        "cropland_n2o_organic = n2o_organic_emissions[n2o_organic_emissions['Item'] == 'Cropland organic soils'].drop(columns=['Element', 'Element Code', 'Item', 'Item Code (CPC)', 'Source', 'Source Code', 'Unit', 'Flag Description', 'Note', 'Flag'])\n",
        "grassland_n2o_organic = n2o_organic_emissions[n2o_organic_emissions['Item'] == 'Grassland organic soils'].drop(columns=['Element', 'Element Code', 'Item', 'Item Code (CPC)', 'Source', 'Source Code', 'Unit', 'Flag Description', 'Note', 'Flag'])\n",
        "\n",
        "# Rename 'Items' columns for these two dataframes\n",
        "cropland_n2o_organic.rename(columns={'Value': 'Cropland Organic n2o emissions (Tonnes) for the year'}, inplace=True)\n",
        "grassland_n2o_organic.rename(columns={'Value': 'Grassland Organic n2o emissions (Tonnes) for the year'}, inplace=True)\n",
        "\n",
        "n2o_organic_emissions = pd.merge(cropland_n2o_organic, grassland_n2o_organic, on=['Area', 'Year'])\n",
        "n2o_organic_emissions['Cropland Organic n2o emissions (Tonnes) for the year'] *= 1000\n",
        "n2o_organic_emissions['Grassland Organic n2o emissions (Tonnes) for the year'] *= 1000\n",
        "\n",
        "# Merge crop_ch4_emissions and crop_n2o_emissions on common columns\n",
        "crop_emissions_merged = pd.merge(crop_ch4_emissions, crop_n2o_emissions, on=['Area', 'Year'])\n",
        "\n",
        "# Merge co2_organic_emissions and n2o_organic_emissions on common columns\n",
        "organic_emissions_merged = pd.merge(co2_organic_emissions, n2o_organic_emissions, on=['Area', 'Year'])\n",
        "\n",
        "# Step 8: Merge crop_emissions_merged and organic_emissions_merged on common columns\n",
        "cleaned_emissions = pd.merge(crop_emissions_merged, organic_emissions_merged, on=['Area', 'Year'])\n",
        "\n",
        "\n",
        "# Export the final_emissions DataFrame to CSV\n",
        "#cleaned_emissions.to_csv('cleaned_emissions.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2bfbbc8-347c-4eb8-ba97-1b952c1afe26",
      "metadata": {
        "id": "b2bfbbc8-347c-4eb8-ba97-1b952c1afe26"
      },
      "source": [
        "### `Employment` data preparation\n",
        "\n",
        "- Drop the `Domain Code` and `Domain` columns.  \n",
        "- Drop the `Indicator Code` column.\n",
        "- Drop the `Sex Code` and `Sex` columns.\n",
        "- Drop the `Element Code` and `Element` columns.\n",
        "- Drop the `Source Code` and `Source` columns.\n",
        "- Drop the `Flag` and `Flag Description` column.\n",
        "- Drop the `Note` column.\n",
        "\n",
        "- Use the `Indicator` column to split the `Employment` field into two datasets `weekly_hours` and `agric_employment` on the values;\n",
        "      - `Mean weekly hours worked per employed person in agriculture, forestry and fishing`.\n",
        "      - `Employment in agriculture, forestry and fishing`. Proceed to drop the `Indicator` columns for both.\n",
        "- Incorporate the `Unit` column to the `Value` column for both. (`No` for normal number, `1000 No` for thousand number, multiply all the entries in the `Value` column for the `agric_employment` dataset). Rename the `Values` column for both to `Mean weekly hours worked per employed person in agriculture, forestry and fishing` and `Employment in agriculture, forestry and fishing` respectively.\n",
        "\n",
        "- Merge on similar columns  (`Area Code`, `Area`, `Year Code`, `Year`)\n",
        "\n",
        "- Remaining - `Area Code`, `Area`, `Year Code`, `Year`, `Mean weekly hours worked per employed person in agriculture, forestry and fishing` and `Employment in agriculture, forestry and fishing`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3710e19-ddea-40d8-8083-5c17d32ba550",
      "metadata": {
        "id": "b3710e19-ddea-40d8-8083-5c17d32ba550"
      },
      "outputs": [],
      "source": [
        "# Drop redundant columns\n",
        "employment_cleaned = employment.drop(columns=['Domain Code', 'Domain', 'Indicator Code', 'Sex Code', 'Sex',\n",
        "                                              'Element Code', 'Element', 'Source Code', 'Source',\n",
        "                                              'Flag', 'Flag Description', 'Note', 'Year Code', 'Area Code (M49)'])\n",
        "\n",
        "# Split the DataFrame based on 'Indicator' values\n",
        "agric_employment = employment_cleaned[employment_cleaned['Indicator'] == 'Employment in agriculture, forestry and fishing - ILO modelled estimates'].copy()\n",
        "\n",
        "# Drop the 'Indicator' column\n",
        "agric_employment.drop(columns=['Indicator', 'Unit'], inplace=True)\n",
        "\n",
        "# Incorporate the 'Unit' column to 'Value' for agric_employment and rename columns\n",
        "agric_employment['Value'] *= 1000  # Multiply by 1000 for '1000 No' in 'Unit'\n",
        "agric_employment.rename(columns={'Value': 'Employment in agriculture, forestry and fishing'}, inplace=True)\n",
        "cleaned_employment = agric_employment\n",
        "\n",
        "# Export the final_employment DataFrame to CSV\n",
        "#cleaned_employment.to_csv('cleaned_employment.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddeea8b9-545f-44c5-aa2d-a55f69e9e5f4",
      "metadata": {
        "id": "ddeea8b9-545f-44c5-aa2d-a55f69e9e5f4"
      },
      "source": [
        "### `Exchange rates` data preparation\n",
        "\n",
        "**steps**\n",
        "- Drop the `Domain Code` and `Domain` column.\n",
        "- Drop the `ISO Currency Code (FAO)` column.\n",
        "- Drop the `Currency` column.\n",
        "- Drop the `Element Code` and`Element` column.\n",
        "- Drop the `Months Code` column.\n",
        "- Drop the `Flag` and `Flag Description` column.\n",
        "- Drop the `Unit` column.\n",
        "- Change the `Value` column to `Average Exchage rate (yearly)`.\n",
        "- Aggregate the `Average Exchage rate (yearly)` column to average yearly value by using the `Months` column and drop the `Months` column.\n",
        "- Remaining - `Area Code`, `Area`, `Year Code`, `Year`, `Average Exchage rate (yearly)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c19efba0-a061-493b-bebb-008743aadaf1",
      "metadata": {
        "id": "c19efba0-a061-493b-bebb-008743aadaf1"
      },
      "outputs": [],
      "source": [
        "exchange_rates = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Exchange rate - FAOSTAT_data_en_2-22-2024.csv')\n",
        "\n",
        "# Drop redundant columns\n",
        "exchange_rates_cleaned = exchange_rates.drop(columns=['Domain Code', 'Domain', 'ISO Currency Code (FAO)',\n",
        "                                                      'Currency', 'Element Code', 'Element',\n",
        "                                                      'Months Code', 'Flag', 'Flag Description',\n",
        "                                                      'Unit', 'Area Code (M49)', 'Year Code'])\n",
        "\n",
        "# Rename the 'Value' column to 'Average Exchange rate (yearly)'\n",
        "exchange_rates_cleaned.rename(columns={'Value': 'Average Exchange rate (yearly)'}, inplace=True)\n",
        "\n",
        "# Aggregate 'Average Exchange rate (yearly)' column to average yearly value\n",
        "exchange_rates_cleaned['Average Exchange rate (yearly)'] = exchange_rates_cleaned.groupby(['Area', 'Year'])['Average Exchange rate (yearly)'].transform('mean')\n",
        "\n",
        "# Drop the duplicate rows since the 'transform' function added duplicates\n",
        "exchange_rates_cleaned.drop_duplicates(subset=['Area', 'Year'], inplace=True)\n",
        "\n",
        "# Drop the 'Months' column\n",
        "exchange_rates_cleaned.drop(columns=['Months'], inplace=True)\n",
        "\n",
        "# Keep only required columns\n",
        "cleaned_exchange_rate = exchange_rates_cleaned[['Area', 'Year', 'Average Exchange rate (yearly)']].copy()\n",
        "\n",
        "# Display the first few rows of the final DataFrame\n",
        "#exchange_rates_final.head(50)\n",
        "\n",
        "# Export to a csv file\n",
        "cleaned_exchange_rate.to_csv('cleaned_exchange_rate.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a1ab895-f509-4cfc-950f-b91a6aeefe48",
      "metadata": {
        "id": "9a1ab895-f509-4cfc-950f-b91a6aeefe48"
      },
      "source": [
        "### `Fertilizers Use` data preparation\n",
        "\n",
        "- Drop the `Domain Code` and `Domain` columns.\n",
        "- Drop the `Element Code` and `Element` columns.\n",
        "- Drop the `Year Code` column.\n",
        "- Drop the `Item Code` column.\n",
        "- Drop the `Flag` and `Flag Description` columns.\n",
        "- Change the `Item` column to `Fertilizer Type Used`.\n",
        "- Drop the `Unit` column.\n",
        "- Use the `Item` column to split the dataset into 24 different datasets on.\n",
        "    - `Ammonia, anhydrous`\n",
        "    - `Ammonium nitrate (AN)`\n",
        "    - `Ammonium sulphate`\n",
        "    - `Calcium ammonium nitrate (CAN) and other mixtures with calcium carbonate`\n",
        "    - `Diammonium phosphate (DAP)`\n",
        "    - `Fertilizers n.e.c.`\n",
        "    - `Monoammonium phosphate (MAP))`\n",
        "    - `NPK fertilizers`\n",
        "    -`Other nitrogenous fertilizers, n.e.c.``\n",
        "    - `Other NK compounds`\n",
        "    - `Other NP compounds`\n",
        "    - `Other phosphatic fertilizers, n.e.c`\n",
        "    - `Other potassic fertilizers, n.e.c`\n",
        "    - `Phosphate rock`\n",
        "    - `PK compounds`\n",
        "    - `Potassium chloride (muriate of potash) (MOP)`\n",
        "    - `Potassium nitrate`\n",
        "    - `Potassium sulphate (sulphate of potash) (SOP)`\n",
        "    - `Sodium nitrate`\n",
        "    - `Superphosphates above 35%`\n",
        "    - `Superphosphates, other`\n",
        "    - `Urea`\n",
        "    - `Urea and ammonium nitrate solutions (UAN)`\n",
        "      \n",
        "- Drop the `Item` column and rename the `Value` column to `Amnt of fertilizers used (Tonnes)`.\n",
        "    - `Amnt of Ammonia, anhydrous fertilizers used (Tonnes)`\n",
        "    - `Amnt of Ammonium nitrate (AN) fertilizers used (Tonnes)`\n",
        "    - `Amnt of Ammonium sulphate fertilizers used (Tonnes)`\n",
        "    - `Amnt of Calcium ammonium nitrate (CAN) and other mixtures with calcium carbonate fertilizers used (Tonnes)`\n",
        "    - `Amnt of Diammonium phosphate (DAP) fertilizers used (Tonnes)`\n",
        "    - `Amnt of ertilizers n.e.c. fertilizers used (Tonnes)`\n",
        "    - `Amnt of Monnammonium phosphate (MAP) fertilizers used (Tonnes)`\n",
        "    - `Amnt of NPK fertilizers used (Tonnes)`\n",
        "    - `Amnt of Other nitrogenous fertilizer, n.e.c. fertilizers used (Tonnes)`\n",
        "    - `Amnt of Other NK compounds fertilizers used (Tonnes)`\n",
        "    - `Amnt of Other NP compounds fertilizers used (Tonnes)`\n",
        "    - `Amnt of Other phosphatic fertilizers, n.e.c fertilizers used (Tonnes)`\n",
        "    - `Amnt of Other potassic fertilizers, n.e.c fertilizers used (Tonnes)`\n",
        "    - `Amnt of Phosphate rock fertilizers used (Tonnes)`\n",
        "    - `Amnt of PK compounds fertilizers used (Tonnes)`\n",
        "    - `Amnt of Potassium chloride (muriate of potash) (MOP) fertilizers used (Tonnes)`\n",
        "    - `Amnt of Potassium nitrate fertilizers used (Tonnes)`\n",
        "    - `Amnt of Potassium sulphate (sulphate of potash) (SOP) fertilizers used (Tonnes)`\n",
        "    - `Amnt of Sodium nitrate fertilizers used (Tonnes)`\n",
        "    - `Amnt of Superphosphates above 35% fertilizers used (Tonnes)`\n",
        "    - `Amnt of Superphosphates, other fertilizers used (Tonnes)`\n",
        "    - `Amnt of Urea fertilizers used (Tonnes)`\n",
        "    - `Amnt of Urea and ammonium nitrate solutions (UAN) fertilizers used (Tonnes)`\n",
        "\n",
        "\n",
        "- Aggregate the `Average Exchage rate (yearly)` column to average yearly value by using the `Months` column and drop the `Months` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe1911bb-bb67-44b9-ad00-f12f51bf6121",
      "metadata": {
        "id": "fe1911bb-bb67-44b9-ad00-f12f51bf6121"
      },
      "outputs": [],
      "source": [
        "# Drop redundant columns\n",
        "fertilizers_used_cleaned = fertilizers_used.drop(columns=['Domain Code', 'Domain', 'Item Code',\n",
        "                                                      'Year Code', 'Element Code', 'Element',\n",
        "                                                      'Item Code', 'Flag', 'Flag Description',\n",
        "                                                      'Unit'])\n",
        "# Change the `Item` column into `Fertilizer Type Used'\n",
        "fertilizers_used_cleaned.rename(columns={'Item': 'Fertilizer Type Used'}, inplace=True)\n",
        "\n",
        "# Use the `Item` column to split the dataset into 24 different datasets on\n",
        "ammonia_anhydrous = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Ammonia, anhydrous', :]\n",
        "                     .rename(columns={'Value': 'Amount of Ammonia Anhydrous used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "ammonium_nitrate = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Ammonium nitrate (AN)', :]\n",
        "                     .rename(columns={'Value': 'Amount of Ammonium Nitrate (AN) Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "\n",
        "ammonium_sulphate = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Ammonium sulphate', :]\n",
        "                     .rename(columns={'Value': 'Amount of Ammonium Sulphate Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "calcium_nitrate = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Calcium ammonium nitrate (CAN) and other mixtures with calcium carbonate', :]\n",
        "                     .rename(columns={'Value': 'Amount of Calcium Nitrate/Calcium Carbonate Fertilizers Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "diammonium_phosphate = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Diammonium phosphate (DAP)', :]\n",
        "                     .rename(columns={'Value': 'Amount of Diammonium phosphate (DAP) Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "fertilizers_nec = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Fertilizers n.e.c.', :]\n",
        "                     .rename(columns={'Value': 'Amount of Fertilizers n.e.c. Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "monoammonium_phosphate = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Monoammonium phosphate (MAP)', :]\n",
        "                     .rename(columns={'Value': 'Amount of Monoammonium phosphate (MAP) Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "other_nitro_fertilizers = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Other nitrogenous fertilizers, n.e.c.', :]\n",
        "                     .rename(columns={'Value': 'Amount of Other Nitrogenous Fertilizers Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "other_nk_compounds = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Other NK compounds', :]\n",
        "                     .rename(columns={'Value': 'Amount of Other NK Compounds Fertilizer Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "other_phosphatic_fertilizers = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Other nitrogenous fertilizers, n.e.c.', :]\n",
        "                     .rename(columns={'Value': 'Amount of Other Phosphatic Fertilizers Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "other_potassic_fertilizers = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Other potassic fertilizers, n.e.c.', :]\n",
        "                     .rename(columns={'Value': 'Amount of Other Potassic Fertilizers Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "phosphate_rock_fertilizers = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Phosphate rock', :]\n",
        "                     .rename(columns={'Value': 'Amount of Phosphate Rock Fertilizers Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "pk_compound_fertilizers = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'PK compounds', :]\n",
        "                     .rename(columns={'Value': 'Amount of PK Compounds Fertilizers Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "potassium_chloride = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Potassium chloride (muriate of potash) (MOP)', :]\n",
        "                     .rename(columns={'Value': 'Amount of Potassium Chloride (MOP) Fertilizer Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "potassium_nitrate = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Potassium nitrate', :]\n",
        "                     .rename(columns={'Value': 'Amount of Potassium nitrate Fertilizer Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "potassium_sulphate = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Potassium sulphate (sulphate of potash) (SOP)', :]\n",
        "                     .rename(columns={'Value': 'Amount of Potassium Sulphate (SOP) Fertilizer Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "sodium_nitrate = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Sodium nitrate', :]\n",
        "                     .rename(columns={'Value': 'Amount of Sodium Nitrate Fertilizer Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "superphosphates_35 = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Superphosphates above 35%', :]\n",
        "                     .rename(columns={'Value': 'Amount of Superphosphates (above 35%) Fertilizer Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "superphosphates_other = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Superphosphates, other', :]\n",
        "                     .rename(columns={'Value': 'Amount of Superphosphates other Fertilizer Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "urea = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Urea', :]\n",
        "                     .rename(columns={'Value': 'Amount of Urea Fertilizer Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "urea_uan = (fertilizers_used_cleaned.loc[fertilizers_used_cleaned['Fertilizer Type Used'] == 'Urea and ammonium nitrate solutions (UAN)', :]\n",
        "                     .rename(columns={'Value': 'Amount of Urea and Ammonium Nitrate solutions (UAN) Fertilizer Used (Yearly)'})).drop(columns=['Fertilizer Type Used', 'Area Code (M49)'])\n",
        "\n",
        "# Merge all the dataframes into one\n",
        "df_list = [ammonia_anhydrous, ammonium_nitrate, ammonium_sulphate, calcium_nitrate, diammonium_phosphate, fertilizers_nec, monoammonium_phosphate,\n",
        "           other_nitro_fertilizers, other_nk_compounds, other_phosphatic_fertilizers, other_potassic_fertilizers, phosphate_rock_fertilizers,\n",
        "           pk_compound_fertilizers, potassium_chloride, potassium_nitrate, potassium_sulphate, sodium_nitrate, superphosphates_35,\n",
        "           superphosphates_other, urea, urea_uan]\n",
        "\n",
        "# Merge all DataFrames on 'Year' and 'Area' columns using a left join\n",
        "cleaned_fertilizers = df_list[0]\n",
        "for df in df_list[1:]:\n",
        "    cleaned_fertilizers = pd.merge(cleaned_fertilizers, df, on=['Year', 'Area'], how='left')\n",
        "cleaned_fertilizers.head(50)\n",
        "# Export to csv\n",
        "#cleaned_fertilizers.to_csv('cleaned_fertilizers.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6946364c-3a37-40ac-a926-26501cd6acc1",
      "metadata": {
        "id": "6946364c-3a37-40ac-a926-26501cd6acc1"
      },
      "source": [
        "### `food balances indicators` data preparation\n",
        "\n",
        "- Drop the `Domain Code`, `Domain`, `Area Code (M49)`, `Element Code`, `Item Code (FBS)`,   columns\n",
        "- Use the element column to split the data into 5 different datasets (`export_qty`, `import_qty`, `food`, `losses`, `non_food_uses`) based on unique values;\n",
        "    - `Export Quantity`\n",
        "    - `Import Quantity`\n",
        "    - `Food`\n",
        "    - `Losses`\n",
        "    - `Other uses (non-food)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "528cf149-b9c9-4f7f-8f75-c5ba39a124eb",
      "metadata": {
        "id": "528cf149-b9c9-4f7f-8f75-c5ba39a124eb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "12a2bbe3-3490-4ea5-b8da-956412410aa4",
      "metadata": {
        "id": "12a2bbe3-3490-4ea5-b8da-956412410aa4"
      },
      "source": [
        "### `Food Security Indicators` data preparation\n",
        "\n",
        "- Drop the `Domain Code`, `Domain`, `Area Code (M49)`, `Element`, `Element Code`, `Item Code`, `Flag`, and `Flag Description` columns,\n",
        "\n",
        "- Use the `Item` column to split the dataframe into 4 dataframes (`food_prod_variability`, `food_supply_variability`, `political_stability`, `anemia_prevalence`) on the unique values;\n",
        "    -  `Per capita food production variability (constant 2014-2016 thousand int$ per capita)`\n",
        "        - for this `food_prod_variability` dataframe, drop the `Item` and `Unit` column.\n",
        "        - Multiply the `Value` column by 1000.\n",
        "        - Rename the `Value` column to `Per Capita Food Production Value (International Dollar)`\n",
        "    -  `Per capita food supply variability (kcal/cap/day)`\n",
        "        - for this `food_supply_variability` dataframe, , drop the `Item` and `Unit` column.\n",
        "        - Multiply the `Value` column by 1000.\n",
        "        - Rename the `Value` column to `Per Capita Food Supply Value (Calories per Capita Per Day)`\n",
        "    - `Political stability and absence of violence/terrorism (index)`\n",
        "        - for this`political_stability` dataframe, , drop the `Item` and `Unit` column.\n",
        "        - Rename the `Value` column to `Political stability and absence of violence/terrorism (index)`\n",
        "    - `Prevalence of anemia among women of reproductive age (15-49 years)`\n",
        "        - for this `anemia_prevalence`) dataframe, , drop the `Item` and `Unit` column.\n",
        "        - Rename the `Value` column to `Percentage Prevalence of anemia among women of reproductive age (15-49 years)`\n",
        "     \n",
        "- Merge the four dataframes (`food_prod_variability`, `food_supply_variability`, `political_stability`, and `anemia_prevalence`) on common columns `Year` and `Area` to get the `fsi_final_merge` dataframe.\n",
        "- Export this dataframe to `cleaned_fsi` csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb83ea6-eaad-4571-ac2d-10542edd87d6",
      "metadata": {
        "id": "5eb83ea6-eaad-4571-ac2d-10542edd87d6"
      },
      "outputs": [],
      "source": [
        "fsi = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Food security indicators  - FAOSTAT_data_en_2-22-2024.csv')\n",
        "\n",
        "# Drop redundant columns\n",
        "fsi.drop(columns=['Domain Code', 'Domain', 'Area Code (M49)', 'Element', 'Element Code', 'Item Code', 'Flag', 'Flag Description', 'Note', 'Year Code'], inplace=True)\n",
        "\n",
        "# Split DataFrame based on 'Item' column values\n",
        "food_prod_variability = fsi[fsi['Item'] == 'Per capita food production variability (constant 2014-2016 thousand int$ per capita)'].drop(columns=['Item', 'Unit'])\n",
        "food_prod_variability['Value'] *= 1000\n",
        "food_prod_variability.rename(columns={'Value': 'Per Capita Food Production Value (International Dollar)'}, inplace=True)\n",
        "\n",
        "food_supply_variability = fsi[fsi['Item'] == 'Per capita food supply variability (kcal/cap/day)'].drop(columns=['Item', 'Unit'])\n",
        "food_supply_variability['Value'] *= 1000\n",
        "food_supply_variability.rename(columns={'Value': 'Per Capita Food Supply Value (Calories per Capita Per Day)'}, inplace=True)\n",
        "\n",
        "political_stability = fsi[fsi['Item'] == 'Political stability and absence of violence/terrorism (index)'].drop(columns=['Item', 'Unit'])\n",
        "political_stability.rename(columns={'Value': 'Political stability and absence of violence/terrorism (index)'}, inplace=True)\n",
        "\n",
        "anemia_prevalence = fsi[fsi['Item'] == 'Prevalence of anemia among women of reproductive age (15-49 years)'].drop(columns=['Item', 'Unit'])\n",
        "anemia_prevalence.rename(columns={'Value': 'Percentage Prevalence of anemia among women of reproductive age (15-49 years)'}, inplace=True)\n",
        "\n",
        "# Merge the DataFrames back on common columns 'Year' and 'Area'\n",
        "fsi_final_merge = pd.merge(food_prod_variability, food_supply_variability, on=['Year', 'Area'])\n",
        "fsi_final_merge = pd.merge(fsi_final_merge, political_stability, on=['Year', 'Area'])\n",
        "cleaned_fsi = pd.merge(fsi_final_merge, anemia_prevalence, on=['Year', 'Area'])\n",
        "\n",
        "cleaned_fsi.head(50)\n",
        "\n",
        "# Export to CSV\n",
        "#cleaned_fsi.to_csv('cleaned_fsi.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d852df9a-6c8b-4242-8cbe-c7be32323f91",
      "metadata": {
        "id": "d852df9a-6c8b-4242-8cbe-c7be32323f91"
      },
      "source": [
        "### `Food Trade Indicators` data preparation\n",
        "\n",
        "- Drop the `Domain Code`, `Domain`, `Area Code (M49)`, `Year Code`, `Item Code (CPC)`, `Element Code`, `Unit`, `Flag`, `Flag Description`, `Note`\n",
        "\n",
        "- Multiply all values in the `Value` column by `1000`\n",
        "- Use the `Element` column to split it into 2 different dataframes(`export_value` and `import_value`) based on unqiue values;\n",
        "    - `Export Value`\n",
        "    - `Import Value`\n",
        "\n",
        "    - For the `export_value` dataframe, drop the `Element` column.\n",
        "    - Use the `Item` column to split into 5 dataframes (`fruits_and_veggies`, `non_food`, `other_food`, `sugar_and_honey`, `tobacco`) based on information-rich values;\n",
        "        - `Fruit and Vegetables`\n",
        "        - `Non-food`\n",
        "        - `Other food`\n",
        "        - `Sugar and Honey`\n",
        "        - `Tobacco`\n",
        "     \n",
        "        - Drop the `Item` column for all 5 dataframes.\n",
        "        - Rename the `Values` column for each of the 5 dataframes as follows;\n",
        "            - `Export Value of Fruits and Vegetables`\n",
        "            - `Export Value of Non-food Items`\n",
        "            - `Export Value of Other food Items (USD)`\n",
        "            - `Export Value of Sugar and Honey Items (USD)`\n",
        "            - `Export Value of Tobacco (USD)`\n",
        "        - merge them back on common columns `Year` and `Area` to get `export_merged` dataframe.\n",
        "    - For the `import_value` dataframe, drop the `Element` column.\n",
        "    - Use the `Item` column to split the dataframe into 12 dataframes(`import_alcoholic_beverages`, `import_cereals_and_prep`, `import_dairy`, `import_fats_and_oils`, `import_fruits_and_veggies`, `import_meats`, `import_non_alcohols`, `import_non_edible_fats`, `import_non_food`, `import_other_food`, `import_sugar_and_honey`, `import_tobacco`);\n",
        "        - `Alcoholic Beverages`\n",
        "        - `Cereals and Preparations`\n",
        "        - `Dairy Products and Eggs`\n",
        "        - `Fats and Oils (excluding Butter)`\n",
        "        - `Fruit and Vegetables`\n",
        "        - `Meat and Meat Preparations`\n",
        "        - `Non-alcoholic Beverages`\n",
        "        - `Non-edible Fats and Oils`\n",
        "        - `Non-food`\n",
        "        - `Other food`\n",
        "        - `Sugar and Honey`\n",
        "        - `Tobacco` respectively\n",
        "    - Drop the `Item` column for all 12 dataframes.\n",
        "    - Rename the `Values` column for each of the 12 dataframes to;\n",
        "        - `Import Value of Alcoholic Beverages (USD)`\n",
        "        - `Import Value of Cereals and Preparations (USD)`\n",
        "        - `Import Value of Dairy Products and Eggs (USD)`\n",
        "        - `Import Value of Fats and Oils (excluding Butter) (USD)`\n",
        "        - `Import Value of Fruit and Vegetables (USD)`\n",
        "        - `Import Value of Meat and Meat Preparations (USD)`\n",
        "        - `Import Value of Non-alcoholic Beverages (USD)`\n",
        "        - `Import Value of Non-edible Fats and Oils (USD)`\n",
        "        - `Import Value of Non-food (USD)`\n",
        "        - `Import Value of Other food (USD)`\n",
        "        - `Import Value of Sugar and Honey (USD)`\n",
        "        - `Import Value of Tobacco (USD)`\n",
        "    - merge the 12 dataframes back on common columns `Year` and `Area` to get `import_merged` dataframe.\n",
        "- merge the `import_merged` and `export_merged` dataframes back on common columns `Year` and `Area` to get `final_fti_merged` dataframe.\n",
        "- Export to csv file as `cleaned_fti`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ce255f-e563-4c17-a023-781c7b7a322c",
      "metadata": {
        "id": "88ce255f-e563-4c17-a023-781c7b7a322c"
      },
      "outputs": [],
      "source": [
        "fti = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Food trade indicators - FAOSTAT_data_en_2-22-2024.csv')\n",
        "\n",
        "# Drop specified columns\n",
        "fti.drop(columns=['Domain Code', 'Domain', 'Area Code (M49)', 'Year Code', 'Item Code (CPC)',\n",
        "                  'Element Code', 'Unit', 'Flag', 'Flag Description', 'Note'], inplace=True)\n",
        "\n",
        "# Multiply all values in the 'Value' column by 1000\n",
        "fti['Value'] *= 1000\n",
        "\n",
        "# Split DataFrame based on 'Element' column values\n",
        "export_value = fti[fti['Element'] == 'Export Value'].drop(columns=['Element'])\n",
        "import_value = fti[fti['Element'] == 'Import Value'].drop(columns=['Element'])\n",
        "\n",
        "# Split 'export_value' DataFrame based on 'Item' column values\n",
        "fruits_and_veggies = export_value[export_value['Item'] == 'Fruit and Vegetables'].drop(columns=['Item']).rename(columns={'Value': 'Export Value of Fruits and Vegetables (USD)'})\n",
        "non_food = export_value[export_value['Item'] == 'Non-food'].drop(columns=['Item']).rename(columns={'Value': 'Export Value of Non-food Items (USD)'})\n",
        "other_food = export_value[export_value['Item'] == 'Other food'].drop(columns=['Item']).rename(columns={'Value': 'Export Value of Other food Items (USD)'})\n",
        "sugar_and_honey = export_value[export_value['Item'] == 'Sugar and Honey'].drop(columns=['Item']).rename(columns={'Value': 'Export Value of Sugar and Honey Items (USD)'})\n",
        "tobacco = export_value[export_value['Item'] == 'Tobacco'].drop(columns=['Item']).rename(columns={'Value': 'Export Value of Tobacco (USD)'})\n",
        "\n",
        "# Merge the 'export_value' DataFrames back on 'Year' and 'Area' columns\n",
        "export_merged = pd.merge(fruits_and_veggies, non_food, on=['Year', 'Area'])\n",
        "export_merged = pd.merge(export_merged, other_food, on=['Year', 'Area'])\n",
        "export_merged = pd.merge(export_merged, sugar_and_honey, on=['Year', 'Area'])\n",
        "export_merged = pd.merge(export_merged, tobacco, on=['Year', 'Area'])\n",
        "\n",
        "# Split 'import_value' DataFrame based on 'Item' column values\n",
        "import_alcoholic_beverages = import_value[import_value['Item'] == 'Alcoholic Beverages'].drop(columns=['Item']).rename(columns={'Value': 'Import Value of Alcoholic Beverages (USD)'})\n",
        "import_cereals_and_prep = import_value[import_value['Item'] == 'Cereals and Preparations'].drop(columns=['Item']).rename(columns={'Value': 'Import Value of Cereals and Preparations (USD)'})\n",
        "import_dairy = import_value[import_value['Item'] == 'Dairy Products and Eggs'].drop(columns=['Item']).rename(columns={'Value': 'Import Value of Dairy Products and Eggs (USD)'})\n",
        "import_fats_and_oils = import_value[import_value['Item'] == 'Fats and Oils (excluding Butter)'].drop(columns=['Item']).rename(columns={'Value': 'Import Value of Fats and Oils (excluding Butter) (USD)'})\n",
        "import_fruits_and_veggies = import_value[import_value['Item'] == 'Fruit and Vegetables'].drop(columns=['Item']).rename(columns={'Value': 'Import Value of Fruit and Vegetables (USD)'})\n",
        "import_meats = import_value[import_value['Item'] == 'Meat and Meat Preparations'].drop(columns=['Item']).rename(columns={'Value': 'Import Value of Meat and Meat Preparations (USD)'})\n",
        "import_non_alcohols = import_value[import_value['Item'] == 'Non-alcoholic Beverages'].drop(columns=['Item']).rename(columns={'Value': 'Import Value of Non-alcoholic Beverages (USD)'})\n",
        "import_non_edible_fats = import_value[import_value['Item'] == 'Non-edible Fats and Oils'].drop(columns=['Item']).rename(columns={'Value': 'Import Value of Non-edible Fats and Oils (USD)'})\n",
        "import_non_food = import_value[import_value['Item'] == 'Non-food'].drop(columns=['Item']).rename(columns={'Value': 'Import Value of Non-food (USD)'})\n",
        "import_other_food = import_value[import_value['Item'] == 'Other food'].drop(columns=['Item']).rename(columns={'Value': 'Import Value of Other food (USD)'})\n",
        "import_sugar_and_honey = import_value[import_value['Item'] == 'Sugar and Honey'].drop(columns=['Item']).rename(columns={'Value': 'Import Value of Sugar and Honey (USD)'})\n",
        "import_tobacco = import_value[import_value['Item'] == 'Tobacco'].drop(columns=['Item']).rename(columns={'Value': 'Import Value of Tobacco (USD)'})\n",
        "\n",
        "# Merge the 'import_value' DataFrames back on 'Year' and 'Area' columns\n",
        "import_merged = pd.merge(import_alcoholic_beverages, import_cereals_and_prep, on=['Year', 'Area'])\n",
        "import_merged = pd.merge(import_merged, import_dairy, on=['Year', 'Area'])\n",
        "import_merged = pd.merge(import_merged, import_fats_and_oils, on=['Year', 'Area'])\n",
        "import_merged = pd.merge(import_merged, import_fruits_and_veggies, on=['Year', 'Area'])\n",
        "import_merged = pd.merge(import_merged, import_meats, on=['Year', 'Area'])\n",
        "import_merged = pd.merge(import_merged, import_non_alcohols, on=['Year', 'Area'])\n",
        "import_merged = pd.merge(import_merged, import_non_edible_fats, on=['Year', 'Area'])\n",
        "import_merged = pd.merge(import_merged, import_non_food, on=['Year', 'Area'])\n",
        "import_merged = pd.merge(import_merged, import_other_food, on=['Year', 'Area'])\n",
        "import_merged = pd.merge(import_merged, import_sugar_and_honey, on=['Year', 'Area'])\n",
        "import_merged = pd.merge(import_merged, import_tobacco, on=['Year', 'Area'])\n",
        "\n",
        "# Merge the 'export_merged' and 'import_merged' DataFrames back on 'Year' and 'Area' columns\n",
        "cleaned_fti = pd.merge(export_merged, import_merged, on=['Year', 'Area'])\n",
        "\n",
        "# Sort the DataFrame by the 'Area' and `Year` column\n",
        "cleaned_fti = cleaned_fti.sort_values(by=['Area', 'Year'])\n",
        "cleaned_fti.head(50)\n",
        "# Export to CSV\n",
        "#sorted_fti.to_csv('cleaned_fti.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2557da2a-aa85-435b-bf92-eaf10217e4ac",
      "metadata": {
        "id": "2557da2a-aa85-435b-bf92-eaf10217e4ac"
      },
      "source": [
        "### `Foreign Direct Investment` data preparation\n",
        "\n",
        "- Drop the `Domain`, `Domain Code`, `Area Code (M49)`, `Element Code`, `Element`, `Item Code`, `Year Code`, `Unit`, `Flag`, `Flag Description`, `Note`\n",
        "- Multiply each value in the `Value` column by 1000000\n",
        "\n",
        "- The `Item` column has 6 different unique values;\n",
        "    - `FDI inflows to Agriculture, Forestry and Fishing`\n",
        "    - `FDI inflows to Food, Beverages and Tobacco`\n",
        "    - `FDI outflows to Agriculture, Forestry and Fishing`\n",
        "    - `FDI outflows to Food, Beverages and Tobacco`\n",
        "    - `Total FDI inflows`\n",
        "    - `Total FDI outflows`\n",
        "\n",
        "    - Due to inconsistencies, only the `Total FDI inflows` and `Total FDI outflows` values in the `Item` column will be considered.\n",
        "\n",
        "    - Use these two values `Total FDI inflows` and `Total FDI outflows` to get two dataframes (total_fdi_inflows) and (total_fdi_outflows).\n",
        "    - Dorop the `Item` column for both and rename the `Value` column for each to;\n",
        "        - `Total FDI Inflows (Dollars)`\n",
        "        - `Total FDI Outflows (Dollars)`\n",
        "- Merge the `total_fdi_inflows` and `total_fdi_outflows` on common columns `Area` and `Year` to get final dataframe `fdi_merged`.\n",
        "- Export to csv called `cleaned_fdi`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c857828c-5861-4faf-b514-2b6bec8ffa42",
      "metadata": {
        "id": "c857828c-5861-4faf-b514-2b6bec8ffa42"
      },
      "outputs": [],
      "source": [
        "fdi = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Foreign direct investment - FAOSTAT_data_en_2-27-2024.csv')\n",
        "\n",
        "# Drop specified columns\n",
        "fdi.drop(columns=['Domain', 'Domain Code', 'Area Code (M49)', 'Element Code', 'Element',\n",
        "                  'Item Code', 'Year Code', 'Unit', 'Flag', 'Flag Description', 'Note'], inplace=True)\n",
        "\n",
        "# Multiply 'Value' column by 1000000\n",
        "fdi['Value'] *= 1000000\n",
        "\n",
        "# Filter rows based on 'Item' column values\n",
        "total_fdi_inflows = fdi[fdi['Item'] == 'Total FDI inflows'].drop(columns=['Item']).rename(columns={'Value': 'Total FDI Inflows (Dollars)'})\n",
        "total_fdi_outflows = fdi[fdi['Item'] == 'Total FDI outflows'].drop(columns=['Item']).rename(columns={'Value': 'Total FDI Outflows (Dollars)'})\n",
        "\n",
        "# Merge the 'total_fdi_inflows' and 'total_fdi_outflows' DataFrames on 'Area' and 'Year' columns\n",
        "cleaned_fdi = pd.merge(total_fdi_inflows, total_fdi_outflows, on=['Area', 'Year'])\n",
        "\n",
        "#fdi_merged.head(50)\n",
        "\n",
        "# Export to CSV\n",
        "#fdi_merged.to_csv('cleaned_fdi.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b17927e-d154-45fa-8434-ef95e4dfcb0c",
      "metadata": {
        "id": "7b17927e-d154-45fa-8434-ef95e4dfcb0c"
      },
      "source": [
        "### `Land Temperature Change` data preparation\n",
        "\n",
        "- Drop the `Domain Code`, `Domain`, `Area Code (M49)`, `Element Code`, `Months Code`, `Year Code`, `Unit`, `Flag`, `Flag Description` columns.\n",
        "\n",
        "- Use the `Element` to split into two dataframes (`standard_dev` and `temp_change`) due to unique values;\n",
        "    - `Standard Deviation`\n",
        "    -  `Temperature change`\n",
        "\n",
        "    -  For the `standard_dev` dataframe, use the `Months` column to split it into 5 dataframes (`dec_jan_feb`, `jun_jul_aug`, `mar_apr_may`, `meterorlogical_year`, `sep_oct_nov`) based on unique values;\n",
        "        - `Dec-Jan-Feb`\n",
        "        - `Jun-Jul-Aug`\n",
        "        - `Mar-Apr-May`\n",
        "        - `Meteorological year`\n",
        "        - `Sep-Oct-Nov`\n",
        "     \n",
        "        - For these five dataframes (`sd_dec_jan_feb`, `sd_jun_jul_aug`, `sd_mar_apr_may`, `sd_meterorlogical_year`, `sd_sep_oct_nov`) drop the `Months` column and rename the `Values` column to;\n",
        "        - `Standard Deviation of Change In Temperature between Dec, Jan and Feb (℃)`\n",
        "        - `Standard Deviation of Change In Temperature between June, July and August (℃)`\n",
        "        - `Standard Deviation of Change In Temperature between March, April and May (℃)`\n",
        "        - `Standard Deviation of Change In Temperature in Metereological Year (℃)`\n",
        "        - `Standard Deviation of Change In Temperature between September, October and December (℃)` repectively.\n",
        "     \n",
        "        - Merge them all back on the `Area` and `Year` columns to form the `sd_merged` dataframe.\n",
        "          \n",
        "    - For the `temp_change` dataframe, use the `Months` column to split it into 5 dataframes (`dec_jan_feb`, `jun_jul_aug`, `mar_apr_may`, `metereological_year`, `sep_oct_nov`) based on unique values;\n",
        "        - `Dec-Jan-Feb`\n",
        "        - `Jun-Jul-Aug`\n",
        "        - `Mar-Apr-May`\n",
        "        - `Metereological year`\n",
        "        - `Sep-Oct-Nov`\n",
        "     \n",
        "        - For these five dataframes (`temp_dec_jan_feb`, `temp_jun_jul_aug`, `temp_mar_apr_may`, `temp_metereological_year`, `temp_sep_oct_nov`) drop the `Months` column and rename the `Values` column to;\n",
        "        - `Change In Temperature between Dec, Jan and Feb (℃)`\n",
        "        - `Change In Temperature between June, July and August (℃)`\n",
        "        - `Change In Temperature between March, April and May (℃)`\n",
        "        - `Change In Temperature in Meterological Year (℃)`\n",
        "        - `Change In Temperature between September, October and December (℃)` repectively.\n",
        "        - Merge them all back on the `Area` and `Year` columns to form the `temp_merged` dataframe.\n",
        "\n",
        "- Merge the `sd_merged` and `temp_merged` dataframes on `Year` and `Area` columns to form the `Land_use_merged` dataframe.\n",
        "- Export this to a dataframe called `cleaned_land_use` dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "140e1f78-b5bb-4ba4-adfc-6012d5807776",
      "metadata": {
        "id": "140e1f78-b5bb-4ba4-adfc-6012d5807776"
      },
      "outputs": [],
      "source": [
        "land_temp_change = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Land temperature change - FAOSTAT_data_en_2-27-2024.csv')\n",
        "\n",
        "land_temp_change.drop(columns=['Domain Code', 'Domain', 'Area Code (M49)', 'Element Code','Months Code',\n",
        "                       'Year Code', 'Unit', 'Flag', 'Flag Description'], inplace=True)\n",
        "\n",
        "# Split DataFrame based on 'Element' column values\n",
        "standard_dev = land_temp_change[land_temp_change['Element'] == 'Standard Deviation']\n",
        "temp_change = land_temp_change[land_temp_change['Element'] == 'Temperature change']\n",
        "\n",
        "# Split 'standard_dev' DataFrame based on 'Months' column values\n",
        "dec_jan_feb = standard_dev[standard_dev['Months'] == 'Dec–Jan–Feb'].drop(columns=['Months', 'Element']).rename(columns={'Value': 'Standard Deviation of Change In Temperature between Dec, Jan and Feb (degree celsius)'})\n",
        "jun_jul_aug = standard_dev[standard_dev['Months'] == 'Jun–Jul–Aug'].drop(columns=['Months', 'Element']).rename(columns={'Value': 'Standard Deviation of Change In Temperature between June, July and August (degree celsius)'})\n",
        "mar_apr_may = standard_dev[standard_dev['Months'] == 'Mar–Apr–May'].drop(columns=['Months', 'Element']).rename(columns={'Value': 'Standard Deviation of Change In Temperature between March, April and May (degree celsius)'})\n",
        "metereological_year = standard_dev[standard_dev['Months'] == 'Meteorological year'].drop(columns=['Months', 'Element']).rename(columns={'Value': 'Standard Deviation of Change In Temperature in Meteorological Year (degree celsius)'})\n",
        "sep_oct_nov = standard_dev[standard_dev['Months'] == 'Sep–Oct–Nov'].drop(columns=['Months', 'Element']).rename(columns={'Value': 'Standard Deviation of Change In Temperature between September, October and November (degree celsius)'})\n",
        "\n",
        "# Merge the 'standard_dev' DataFrames back on 'Area' and 'Year' columns\n",
        "sd_merged = pd.concat([dec_jan_feb, jun_jul_aug, mar_apr_may, metereological_year, sep_oct_nov])\n",
        "sd_merged = sd_merged.groupby(['Area', 'Year']).sum().reset_index()\n",
        "\n",
        "# Split 'temp_change' DataFrame based on 'Months' column values\n",
        "temp_dec_jan_feb = temp_change[temp_change['Months'] == 'Dec–Jan–Feb'].drop(columns=['Months', 'Element']).rename(columns={'Value': 'Change In Temperature between Dec, Jan and Feb (degree celsius)'})\n",
        "temp_jun_jul_aug = temp_change[temp_change['Months'] == 'Jun–Jul–Aug'].drop(columns=['Months', 'Element']).rename(columns={'Value': 'Change In Temperature between June, July and August (degree celsius)'})\n",
        "temp_mar_apr_may = temp_change[temp_change['Months'] == 'Mar–Apr–May'].drop(columns=['Months', 'Element']).rename(columns={'Value': 'Change In Temperature between March, April and May (degree celsius)'})\n",
        "temp_metereological_year = temp_change[temp_change['Months'] == 'Meteorological year'].drop(columns=['Months', 'Element']).rename(columns={'Value': 'Change In Temperature in Meteorological Year (degree celsius)'})\n",
        "temp_sep_oct_nov = temp_change[temp_change['Months'] == 'Sep–Oct–Nov'].drop(columns=['Months', 'Element']).rename(columns={'Value': 'Change In Temperature between September, October and November (degree celsius)'})\n",
        "\n",
        "# Merge the 'temp_change' DataFrames back on 'Area' and 'Year' columns\n",
        "temp_merged = pd.concat([temp_dec_jan_feb, temp_jun_jul_aug, temp_mar_apr_may, temp_metereological_year, temp_sep_oct_nov])\n",
        "temp_merged = temp_merged.groupby(['Area', 'Year']).sum().reset_index()\n",
        "\n",
        "temp_merged = temp_merged.groupby(['Area', 'Year']).sum().reset_index()\n",
        "\n",
        "# Merge the 'sd_merged' and 'temp_merged' DataFrames on 'Year' and 'Area' columns\n",
        "cleaned_land_temp_change = pd.merge(sd_merged, temp_merged, on=['Area', 'Year'])\n",
        "cleaned_land_temp_change.head(50)\n",
        "\n",
        "# Export to CSV\n",
        "#cleaned_land_temp_change.to_csv('cleaned_land_temp_change.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38170612-5c1b-4c10-9a95-8998d28ab560",
      "metadata": {
        "id": "38170612-5c1b-4c10-9a95-8998d28ab560"
      },
      "source": [
        "### `Land Use` data preparation\n",
        "\n",
        "- Drop the `Domain Code`, `Domain`, `Area Code`, `Element Code`, `Element`, `Item Code`, `Year Code`, `Flag`, `Flag Description`, `Note` columns.\n",
        "- Drop the `Unit` column and multiply each value in the `Value` colun by 1000\n",
        "\n",
        "- Use the `Item` column to split the dataframe into 12 Different dataframes (`agric_land`, `agric`, `irrigated_agric_area`, `arable_land`, `country_area`, `cropland`, `irrigated_cropland_area`, `farm_buildings`,`irrigated_forestry_area`, `land_area`, `irrigated_land_area`, `equipped_irrigated_land_area`, `cultivated _perm`, `natural_perm`, `irrigated_perm`, `permanent_crops`, `permanent_meadows`, `temp_crops`, `temp_fallow`, `temp_meadows`) based on the following unique values respectively;\n",
        "    - `Agricultural land`\n",
        "    - `Agriculture`\n",
        "    - `Arable land`\n",
        "    - `Country Area`\n",
        "    - `Cropland`\n",
        "    - `Land area`\n",
        "    - `Land area actually irrigated`\n",
        "    - `Land area equipped for irrigation`\n",
        "    - `Permanent crops`\n",
        "    - `Permanent meadows and pastures`\n",
        "    - `Temporary crops`\n",
        "    - `Temporary fallow`\n",
        "    - `Temporary meadows and pastures`\n",
        "- For each of these 12 dataframes, rename the `Value` columns to;\n",
        "    - `Country Agricultural Land Mass (Hectares)`\n",
        "    - `Country Land Mass for Agriculture Only (Hectares)`\n",
        "    - `Country Arable Land Mass (Hectares)`\n",
        "    - `Country Area Land Mass (Hectares)`\n",
        "    - `Country Cropland Mass (Hectares)`\n",
        "    - `Country Land Area (Hectares)`\n",
        "    - `Country Land Area Actually Irrigates (Hectares)`\n",
        "    - `Country Land Area Equipped for Irrigation (Hectares)`\n",
        "    - `Country Permanent Crops Land Area (Hectares)`\n",
        "    - `Country Meadows and Pastures Total Land Area (Hectares)`\n",
        "    - `Country Total Land Area for Temporary Crops (Hectares)`\n",
        "    - `Country Total Land Area for Temporary Fallow (Hectares)`\n",
        "    - `Country Total Land Area for Temporary Meadows and Pastures (Hectares)`\n",
        "\n",
        "- Then merge the 20 dataframes on the `Year` and `Area` columns to get the final merge dataframe called `land_use_final_merged`\n",
        "- Export to a csv file called `land_use_cleaned`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32adc454-bc24-48bc-ba9e-5d9bec4c481a",
      "metadata": {
        "id": "32adc454-bc24-48bc-ba9e-5d9bec4c481a"
      },
      "outputs": [],
      "source": [
        "# Drop specified columns\n",
        "land_use.drop(columns=['Domain Code', 'Domain', 'Area Code (M49)', 'Element Code', 'Element',\n",
        "                        'Item Code', 'Year Code', 'Flag', 'Flag Description', 'Note', 'Unit'],\n",
        "              inplace=True)\n",
        "\n",
        "# Multiply 'Value' column by 1000\n",
        "land_use['Value'] *= 1000\n",
        "\n",
        "# Split DataFrame based on 'Item' column values\n",
        "agric_land = land_use[land_use['Item'] == 'Agricultural land'].rename(columns={'Value': 'Country Agricultural Land Mass (Hectares)'})\n",
        "agric = land_use[land_use['Item'] == 'Agriculture'].rename(columns={'Value': 'Country Land Mass for Agriculture Only (Hectares)'})\n",
        "arable_land = land_use[land_use['Item'] == 'Arable land'].rename(columns={'Value': 'Country Arable Land Mass (Hectares)'})\n",
        "country_area = land_use[land_use['Item'] == 'Country Area'].rename(columns={'Value': 'Country Area Land Mass (Hectares)'})\n",
        "cropland = land_use[land_use['Item'] == 'Cropland'].rename(columns={'Value': 'Country Cropland Mass (Hectares)'})\n",
        "land_area = land_use[land_use['Item'] == 'Land area'].rename(columns={'Value': 'Country Land Area (Hectares)'})\n",
        "equipped_irrigated_land_area = land_use[land_use['Item'] == 'Land area equipped for irrigation'].rename(columns={'Value': 'Country Land Area Equipped for Irrigation (Hectares)'})\n",
        "permanent_crops = land_use[land_use['Item'] == 'Permanent crops'].rename(columns={'Value': 'Country Permanent Crops Land Area (Hectares)'})\n",
        "permanent_meadows = land_use[land_use['Item'] == 'Permanent meadows and pastures'].rename(columns={'Value': 'Country Meadows and Pastures Total Land Area (Hectares)'})\n",
        "temp_crops = land_use[land_use['Item'] == 'Temporary crops'].rename(columns={'Value': 'Country Total Land Area for Temporary Crops (Hectares)'})\n",
        "temp_fallow = land_use[land_use['Item'] == 'Temporary fallow'].rename(columns={'Value': 'Country Total Land Area for Temporary Fallow (Hectares)'})\n",
        "temp_meadows = land_use[land_use['Item'] == 'Temporary meadows and pastures'].rename(columns={'Value': 'Country Total Land Area for Temporary Meadows and Pastures (Hectares)'})\n",
        "\n",
        "# Merge the 20 dataframes on 'Year' and 'Area' columns\n",
        "dfs_to_merge = [agric_land, agric, arable_land, country_area, cropland, land_area, equipped_irrigated_land_area,\n",
        "                permanent_crops, permanent_meadows, temp_crops,temp_fallow, temp_meadows]\n",
        "\n",
        "land_use_final_merged = pd.concat(dfs_to_merge).groupby(['Year', 'Area']).sum().reset_index()\n",
        "\n",
        "# Drop the `Item` column\n",
        "land_use_final_merged.drop(columns=['Item'], inplace=True)\n",
        "\n",
        "# Sort the DataFrame by the 'Area' and `Year` columns\n",
        "cleaned_land_use = land_use_final_merged.sort_values(by=['Area', 'Year'])\n",
        "\n",
        "# Export to CSV\n",
        "#cleaned_land_use.to_csv('cleaned_land_use.csv', index=False)\n",
        "\n",
        "cleaned_land_use"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f1d3384-4fae-4239-8508-a26bcf991ea9",
      "metadata": {
        "id": "8f1d3384-4fae-4239-8508-a26bcf991ea9"
      },
      "source": [
        "### `Pesticides Use` data preparation\n",
        "\n",
        "- Drop the `Domain Code`, `Domain`, `Area Code (M49)`, `Element Code`, `Item Code`, `Year Code`, `Flag`, `Flag Description` and `Note` columns.\n",
        "- Use the `Element` columns to split it into three dataframes (`agricultural_use`, `per_area cropland`, and `per_agric_value`) based on the unique values;\n",
        "    - `Agricultural Use`,\n",
        "    - `Use per area of cropland`,\n",
        "    - `Use per value of agricultural production`.\n",
        "- For the `agricultural_use` dataframe, use the `Item` column to split it into 7 different dataframes (`pesticides`, `insecticides`, `herbicides`, `fungicides_bactericides`, `fungicides_seed_treatments`, `insecticides_seed_treatments`, `rodenticides`) based on the values;\n",
        "    -  `Pesticides (Total)`\n",
        "    -  `Insecticides`\n",
        "    -  `Herbicides`\n",
        "    -  `Fungicides and Bactericides`\n",
        "    -  `Fungicides – Seed treatments`\n",
        "    -  `Insecticides – Seed Treatments`\n",
        "    -  `Rodenticides`, respectively.\n",
        "\n",
        "    -  For each of these 7 dataframes, drop the `Item` and `Element` columns, rename the `Value` column for each to;\n",
        "        -  `Total Amount of Pesticides (Total) Used for Agriculture`\n",
        "        -  `Total Amount of Insecticides Used (Tonnes) for Agriculture`\n",
        "        -  `Total Amount of Herbicides Used (Tonnes) for Agriculture`\n",
        "        -  `Total Amount of Fungicides and Bactericides Used (Tonnes) for Agriculture`\n",
        "        -  `Total Amount of Fungicides – Seed treatments Used (Tonnes) for Agriculture`\n",
        "        -  `Total Amount of Insecticides – Seed Treatments Used (Tonnes) for Agriculture`\n",
        "        -  `Total Amount of Rodenticides Used (Tonnes) for Agriculture`, respectively.\n",
        "    - Merge back all the 7 dataframes on common columns `Year` and `Area` to get the `agricultural_use_merged` dataframe.\n",
        "\n",
        "- For the `per_area cropland` dataframe, drop the `Item` and `Element` columns. Then divide all the values in the `Value` column by 1000 (to convert from kg/hectare to tonne/hectare). Then rename the `Value` column to `Total Amount of Pesticides(Tonnes) Used per Hectare of Cropland`.\n",
        "\n",
        "- For the `per_agric_value` dataframe, drop the `Item` and `Element` columns. Then divide all the values in the `Value` column by 1000000 (to convert from gram/dollars to Tonne/dollars). Then rename the `Value` column to `Total Amount of Pesticides(Tonnes) Used per per Value of Agricultural Production`.\n",
        "\n",
        "- Merge the `agricultural_use_merged`, `per_area cropland`, and `per_agric_value` dataframes on common columns `Year` and `Area` to get the `pesticides_merged` dataframe.\n",
        "- Export to `pesticides_cleaned` csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d16d338-e623-42e4-85f7-519894d78841",
      "metadata": {
        "id": "4d16d338-e623-42e4-85f7-519894d78841"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load the pesticides DataFrame\n",
        "pesticides = pd.read_csv(r'C:\\Users\\Crowntech\\Documents\\Projects\\Mlp project\\Pesticides use - FAOSTAT_data_en_2-27-2024.csv')\n",
        "\n",
        "# Drop redundant columns\n",
        "pesticides_cleaned = pesticides.drop(columns=['Domain Code', 'Domain', 'Area Code (M49)', 'Element Code',\n",
        "                                              'Item Code', 'Year Code', 'Flag', 'Flag Description', 'Note'])\n",
        "\n",
        "# Split the DataFrame based on 'Element' values\n",
        "agricultural_use = pesticides_cleaned[pesticides_cleaned['Element'] == 'Agricultural Use']\n",
        "per_area_cropland = pesticides_cleaned[pesticides_cleaned['Element'] == 'Use per area of cropland']\n",
        "per_agric_value = pesticides_cleaned[pesticides_cleaned['Element'] == 'Use per value of agricultural production']\n",
        "\n",
        "# Split the 'agricultural_use' DataFrame based on 'Item' values\n",
        "agricultural_use_items = ['Pesticides (Total)', 'Insecticides', 'Herbicides', 'Fungicides and Bactericides',\n",
        "                          'Fungicides – Seed treatments', 'Insecticides – Seed Treatments', 'Rodenticides']\n",
        "\n",
        "agricultural_use_dataframes = {}\n",
        "for item in agricultural_use_items:\n",
        "    df_name = item.lower().replace(\" \", \"_\") + \"_used\"\n",
        "    agricultural_use_dataframes[df_name] = agricultural_use[agricultural_use['Item'] == item].copy()\n",
        "    agricultural_use_dataframes[df_name].rename(columns={'Value': f'Total Amount of {item} Used (Tonnes) for Agriculture'}, inplace=True)\n",
        "    agricultural_use_dataframes[df_name].drop(columns=['Item', 'Element', 'Unit'], inplace=True)\n",
        "\n",
        "# Merge the 7 dataframes from 'agricultural_use_dataframes' on common columns 'Year' and 'Area'\n",
        "agricultural_use_merged = pd.concat(agricultural_use_dataframes.values()).groupby(['Year', 'Area']).sum().reset_index()\n",
        "\n",
        "# Process 'per_area_cropland' DataFrame\n",
        "per_area_cropland.drop(columns=['Item', 'Element', 'Unit'], inplace=True)\n",
        "per_area_cropland['Value'] /= 1000  # Convert kg/hectare to tonne/hectare\n",
        "per_area_cropland.rename(columns={'Value': 'Total Amount of Pesticides(Tonnes) Used per Hectare of Cropland'}, inplace=True)\n",
        "\n",
        "# Process 'per_agric_value' DataFrame\n",
        "per_agric_value.drop(columns=['Item', 'Element', 'Unit'], inplace=True)\n",
        "per_agric_value['Value'] /= 1000000  # Convert gram/dollars to Tonne/dollars\n",
        "per_agric_value.rename(columns={'Value': 'Total Amount of Pesticides(Tonnes) Used per Value of Agricultural Production'}, inplace=True)\n",
        "\n",
        "# Merge the three dataframes on common columns 'Year' and 'Area' to get 'pesticides_merged'\n",
        "pesticides_merged = pd.merge(agricultural_use_merged, per_area_cropland, on=['Year', 'Area'])\n",
        "pesticides_merged = pd.merge(pesticides_merged, per_agric_value, on=['Year', 'Area'])\n",
        "\n",
        "# Sort according to `Area`\n",
        "cleaned_pesticides = pesticides_merged.sort_values(by='Area')\n",
        "cleaned_pesticides.head(50)\n",
        "\n",
        "# Export to 'pesticides_cleaned.csv' file\n",
        "#pesticides_merged.to_csv('cleaned_pesticides.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5f3a983-61af-42e7-814c-525ff906c341",
      "metadata": {
        "id": "a5f3a983-61af-42e7-814c-525ff906c341"
      },
      "source": [
        "### Merge all the cleaned dataframes\n",
        "- `cleaned_land_temp`\n",
        "- `cleaned_exchange_rate`\n",
        "- `cleaned_employment`\n",
        "- `cleaned_emissions`\n",
        "- `cleaned_crop_pi`\n",
        "- `cleaned_consumer_pi`\n",
        "- `cleaned_fsi`\n",
        "- `cleaned_fti`\n",
        "- `cleaned_fdi`\n",
        "- `cleaned_land_use`\n",
        "- `cleaned_pesticides`\n",
        "\n",
        "on common columns `Area` and `Year`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dad59430-9360-4ce8-a799-9d8c8634f75b",
      "metadata": {
        "id": "dad59430-9360-4ce8-a799-9d8c8634f75b"
      },
      "outputs": [],
      "source": [
        "# Convert 'Year' column to the same data type in all DataFrames\n",
        "cleaned_land_temp_change['Year'] = cleaned_land_temp_change['Year'].astype(int)\n",
        "cleaned_exchange_rate['Year'] = cleaned_exchange_rate['Year'].astype(int)\n",
        "cleaned_employment['Year'] = cleaned_employment['Year'].astype(int)\n",
        "cleaned_emissions['Year'] = cleaned_emissions['Year'].astype(int)\n",
        "cleaned_crop_pi['Year'] = cleaned_crop_pi['Year'].astype(int)\n",
        "cleaned_consumer_pi['Year'] = cleaned_consumer_pi['Year'].astype(int)\n",
        "cleaned_fsi['Year'] = cleaned_fsi['Year'].astype(int)\n",
        "cleaned_fti['Year'] = cleaned_fti['Year'].astype(int)\n",
        "cleaned_fdi['Year'] = cleaned_fdi['Year'].astype(int)\n",
        "cleaned_land_use['Year'] = cleaned_land_use['Year'].astype(int)\n",
        "cleaned_pesticides['Year'] = cleaned_pesticides['Year'].astype(int)\n",
        "\n",
        "# Merge DataFrames one by one\n",
        "merged_data = pd.merge(cleaned_land_temp_change, cleaned_exchange_rate, on=['Area', 'Year'], how='outer')\n",
        "merged_data = pd.merge(merged_data, cleaned_employment, on=['Area', 'Year'], how='outer')\n",
        "merged_data = pd.merge(merged_data, cleaned_emissions, on=['Area', 'Year'], how='outer')\n",
        "merged_data = pd.merge(merged_data, cleaned_crop_pi, on=['Area', 'Year'], how='outer')\n",
        "merged_data = pd.merge(merged_data, cleaned_consumer_pi, on=['Area', 'Year'], how='outer')\n",
        "merged_data = pd.merge(merged_data, cleaned_fsi, on=['Area', 'Year'], how='outer')\n",
        "merged_data = pd.merge(merged_data, cleaned_fti, on=['Area', 'Year'], how='outer')\n",
        "merged_data = pd.merge(merged_data, cleaned_fdi, on=['Area', 'Year'], how='outer')\n",
        "merged_data = pd.merge(merged_data, cleaned_land_use, on=['Area', 'Year'], how='outer')\n",
        "merged_data = pd.merge(merged_data, cleaned_pesticides, on=['Area', 'Year'], how='outer')\n",
        "\n",
        "merged_data.head()\n",
        "# Export the merged DataFrame to a CSV file\n",
        "# merged_data.to_csv('merged_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e19d1f-9dc6-41cd-873f-0dbf5422c2ba",
      "metadata": {
        "id": "66e19d1f-9dc6-41cd-873f-0dbf5422c2ba"
      },
      "outputs": [],
      "source": [
        "# Drop rows with Year values not between 2000 and 2019\n",
        "merged_data = merged_data[(merged_data['Year'] >= 2000) & (merged_data['Year'] <= 2019)]\n",
        "\n",
        "# Resetting the index after dropping rows\n",
        "merged_data.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b66924dc-e966-4468-9943-824e846e9e99",
      "metadata": {
        "id": "b66924dc-e966-4468-9943-824e846e9e99"
      },
      "outputs": [],
      "source": [
        "merged_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e1e6b66-068a-4217-a084-d33b17d03012",
      "metadata": {
        "id": "0e1e6b66-068a-4217-a084-d33b17d03012"
      },
      "outputs": [],
      "source": [
        "# Set the display options to show all rows\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "# Check for missing values and display the sum for each column\n",
        "print(merged_data.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "163d995e-bf8c-42fe-a0c1-83484bcee6e2",
      "metadata": {
        "id": "163d995e-bf8c-42fe-a0c1-83484bcee6e2"
      },
      "outputs": [],
      "source": [
        "# Define the target columns\n",
        "target_columns = ['Export Value of Fruits and Vegetables (USD)',\n",
        "                  'Export Value of Non-food Items (USD)',\n",
        "                  'Export Value of Other food Items (USD)',\n",
        "                  'Export Value of Sugar and Honey Items (USD)',\n",
        "                  'Export Value of Tobacco (USD)']\n",
        "\n",
        "merged_data1 = merged_data.drop(columns=target_columns)\n",
        "\n",
        "\n",
        "# Create merged_data2 with columns not in the target columns\n",
        "merged_data2 = merged_data[target_columns]\n",
        "\n",
        "# Drop columns with more than 1000 missing values\n",
        "merged_data1 = merged_data1.dropna(thresh=len(merged_data1) - 1000, axis=1)\n",
        "\n",
        "merged_data = pd.concat([merged_data1, merged_data2], axis=1)\n",
        "\n",
        "merged_data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6acf3b32-feef-4b0c-a50d-e0405376da82",
      "metadata": {
        "id": "6acf3b32-feef-4b0c-a50d-e0405376da82"
      },
      "outputs": [],
      "source": [
        "#Perform time Series interpolation on missing values\n",
        "columns_to_interpolate = merged_data.columns.difference(['Area'])\n",
        "\n",
        "# Convert 'Year' column to datetime index\n",
        "merged_data['Year'] = pd.to_datetime(merged_data['Year'], format='%Y')\n",
        "merged_data.set_index('Year', inplace=True)\n",
        "\n",
        "# Apply time series interpolation to the entire DataFrame\n",
        "merged_data_interpolated = merged_data.interpolate(method='time', axis=0, limit_direction='both')\n",
        "\n",
        "# Reset index of the interpolated DataFrame\n",
        "merged_data_interpolated.reset_index(inplace=True)\n",
        "\n",
        "# Set the display options to show all rows\n",
        "pd.set_option('display.max_columns', None)\n",
        "# Check the resulting DataFrame\n",
        "merged_data_interpolated.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be6358c2-26ca-4be6-a62d-d7309242a5ae",
      "metadata": {
        "id": "be6358c2-26ca-4be6-a62d-d7309242a5ae"
      },
      "outputs": [],
      "source": [
        "#Export to csv\n",
        "#merged_data_interpolated.to_csv('final_merge.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae4ef28d-1b2e-46e2-ba07-0c1ba7ed8699",
      "metadata": {
        "id": "ae4ef28d-1b2e-46e2-ba07-0c1ba7ed8699"
      },
      "outputs": [],
      "source": [
        "# Rename the merged data variable\n",
        "final_merge = merged_data_interpolated"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b2851ea-4097-4179-bc80-250fd4d15439",
      "metadata": {
        "id": "6b2851ea-4097-4179-bc80-250fd4d15439"
      },
      "source": [
        "### Machine Learning 🤖🤖🤖🤖🤖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6e73aea-94bc-4f02-8df1-1ae0a5c92a08",
      "metadata": {
        "id": "d6e73aea-94bc-4f02-8df1-1ae0a5c92a08"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "# Convert categorical columns to numerical columns\n",
        "final_merged_numeric = pd.get_dummies(final_merge)\n",
        "\n",
        "final_merged_numeric.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a2d0efc-afef-4cf0-b006-6e25cae44ba8",
      "metadata": {
        "id": "9a2d0efc-afef-4cf0-b006-6e25cae44ba8"
      },
      "outputs": [],
      "source": [
        "# Separate features and labels\n",
        "target_columns = ['Export Value of Fruits and Vegetables (USD)',\n",
        "                  'Export Value of Non-food Items (USD)',\n",
        "                  'Export Value of Other food Items (USD)',\n",
        "                  'Export Value of Sugar and Honey Items (USD)',\n",
        "                  'Export Value of Tobacco (USD)']\n",
        "\n",
        "# Include the 'Year' column in both features and labels\n",
        "features = final_merged_numeric.drop(target_columns, axis=1)\n",
        "\n",
        "labels = final_merged_numeric[target_columns]\n",
        "labels['Year'] = final_merged_numeric['Year']  # Adding 'Year' to labels\n",
        "\n",
        "features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82220528-8f91-4cb9-a2c1-cd3edede9b3c",
      "metadata": {
        "id": "82220528-8f91-4cb9-a2c1-cd3edede9b3c"
      },
      "outputs": [],
      "source": [
        "labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73a024d8-47a3-4ea3-8b9c-f99eb742c1a5",
      "metadata": {
        "id": "73a024d8-47a3-4ea3-8b9c-f99eb742c1a5"
      },
      "outputs": [],
      "source": [
        "# Convert the NumPy array back to a DataFrame\n",
        "scaled_features_df = pd.DataFrame(features, columns=features.columns)\n",
        "\n",
        "# Separate numeric columns (excluding boolean columns) for scaling\n",
        "numeric_columns = scaled_features_df.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Scale numeric columns only\n",
        "scaler = StandardScaler()\n",
        "scaled_values = scaler.fit_transform(scaled_features_df[numeric_columns])\n",
        "\n",
        "# Convert scaled numeric values back to a DataFrame\n",
        "scaled_numeric_df = pd.DataFrame(scaled_values, columns=numeric_columns)\n",
        "\n",
        "# Combine scaled numeric columns with non-numeric (boolean) columns\n",
        "scaled_features_df[numeric_columns] = scaled_numeric_df\n",
        "\n",
        "# Add the 'Year' column back to the scaled features DataFrame\n",
        "scaled_features_df['Year'] = features['Year']\n",
        "\n",
        "scaled_features_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96833477-b7f7-4502-957f-d0c24e1c4d35",
      "metadata": {
        "id": "96833477-b7f7-4502-957f-d0c24e1c4d35"
      },
      "outputs": [],
      "source": [
        "# Define the year ranges for training and test data\n",
        "train_years = range(2000, 2017)\n",
        "test_years = range(2017, 2020)\n",
        "\n",
        "# Filter the data based on the 'Year' column\n",
        "train_features = scaled_features_df[scaled_features_df['Year'].dt.year.isin(train_years)]\n",
        "train_labels = labels[labels['Year'].dt.year.isin(train_years)].drop(columns='Year')\n",
        "\n",
        "test_features = scaled_features_df[scaled_features_df['Year'].dt.year.isin(test_years)]\n",
        "test_labels = labels[labels['Year'].dt.year.isin(test_years)].drop(columns='Year')\n",
        "\n",
        "# Print the shapes of training and test data to verify\n",
        "print(\"Training Features Shape:\", train_features.shape)\n",
        "print(\"Training Labels Shape:\", train_labels.shape)\n",
        "print(\"Test Features Shape:\", test_features.shape)\n",
        "print(\"Test Labels Shape:\", test_labels.shape)\n",
        "\n",
        "train_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QpoWSCF04t8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpoWSCF04t8e",
        "outputId": "6cc8af97-785c-4804-eedf-b2ee828fff31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O4fFvBYr5KTT",
      "metadata": {
        "id": "O4fFvBYr5KTT"
      },
      "source": [
        "### Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39062682-5d90-485c-8dda-0d4da5a2b712",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39062682-5d90-485c-8dda-0d4da5a2b712",
        "outputId": "4be9846f-6e7e-468e-a99a-5dd9c5f65605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features Shape: (4238, 287)\n",
            "Training Labels Shape: (4238, 5)\n",
            "Test Features Shape: (750, 287)\n",
            "Test Labels Shape: (750, 5)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_features = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/MLP Project/train_features.csv\")\n",
        "train_labels = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/MLP Project/train_labels.csv\")\n",
        "test_features = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/MLP Project/test_features.csv\")\n",
        "test_labels = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/MLP Project/test_labels.csv\")\n",
        "\n",
        "train_features['Year'] = pd.to_datetime(train_features['Year'])\n",
        "train_features['Year_numeric'] = train_features['Year'].dt.year\n",
        "test_features['Year'] = pd.to_datetime(test_features['Year'])\n",
        "test_features['Year_numeric'] = test_features['Year'].dt.year\n",
        "\n",
        "\n",
        "# Drop the original datetime column\n",
        "train_features.drop('Year', axis=1, inplace=True)\n",
        "test_features.drop('Year', axis=1, inplace=True)\n",
        "\n",
        "X_train = np.asarray(train_features).astype(np.float32)\n",
        "y_train = np.asarray(train_labels).astype(np.float32)\n",
        "X_test = np.asarray(test_features).astype(np.float32)\n",
        "y_test = np.asarray(test_labels).astype(np.float32)\n",
        "\n",
        "\n",
        "# Print the shapes of training and test data to verify\n",
        "print(\"Training Features Shape:\", X_train.shape)\n",
        "print(\"Training Labels Shape:\", y_train.shape)\n",
        "print(\"Test Features Shape:\", X_test.shape)\n",
        "print(\"Test Labels Shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LY3BJ_E35y5z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LY3BJ_E35y5z",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "34c8918f-312e-4c23-ff11-b67ca1f87f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "133/133 [==============================] - 5s 17ms/step - loss: 17688762747753332736.0000\n",
            "Epoch 2/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 16984592620372099072.0000\n",
            "Epoch 3/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 16927730277030035456.0000\n",
            "Epoch 4/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 16915246422008266752.0000\n",
            "Epoch 5/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 16882925178198163456.0000\n",
            "Epoch 6/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 16836249810087444480.0000\n",
            "Epoch 7/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 16819607602089426944.0000\n",
            "Epoch 8/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 16811715307625250816.0000\n",
            "Epoch 9/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 16739289377192017920.0000\n",
            "Epoch 10/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 16625498719810224128.0000\n",
            "Epoch 11/50\n",
            "133/133 [==============================] - 4s 26ms/step - loss: 16312825100661424128.0000\n",
            "Epoch 12/50\n",
            "133/133 [==============================] - 3s 22ms/step - loss: 15168717281262829568.0000\n",
            "Epoch 13/50\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 14965659473845157888.0000\n",
            "Epoch 14/50\n",
            "133/133 [==============================] - 3s 21ms/step - loss: 14830695521047281664.0000\n",
            "Epoch 15/50\n",
            "133/133 [==============================] - 3s 21ms/step - loss: 14747875907196682240.0000\n",
            "Epoch 16/50\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 14730557499547582464.0000\n",
            "Epoch 17/50\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 14560511429242257408.0000\n",
            "Epoch 18/50\n",
            "133/133 [==============================] - 3s 26ms/step - loss: 14580027760635281408.0000\n",
            "Epoch 19/50\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 14537025860872962048.0000\n",
            "Epoch 20/50\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 14469120022741516288.0000\n",
            "Epoch 21/50\n",
            "133/133 [==============================] - 3s 24ms/step - loss: 14473212405020098560.0000\n",
            "Epoch 22/50\n",
            "133/133 [==============================] - 4s 29ms/step - loss: 14441826845605232640.0000\n",
            "Epoch 23/50\n",
            "133/133 [==============================] - 4s 28ms/step - loss: 14446288663790747648.0000\n",
            "Epoch 24/50\n",
            "133/133 [==============================] - 3s 19ms/step - loss: 14351964859778727936.0000\n",
            "Epoch 25/50\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 14378519165101146112.0000\n",
            "Epoch 26/50\n",
            "133/133 [==============================] - 3s 22ms/step - loss: 14238821814745694208.0000\n",
            "Epoch 27/50\n",
            "133/133 [==============================] - 3s 22ms/step - loss: 14224973465793855488.0000\n",
            "Epoch 28/50\n",
            "133/133 [==============================] - 4s 33ms/step - loss: 14133239011665248256.0000\n",
            "Epoch 29/50\n",
            "133/133 [==============================] - 3s 23ms/step - loss: 14066541536812728320.0000\n",
            "Epoch 30/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 13955167605988786176.0000\n",
            "Epoch 31/50\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 13994912752309633024.0000\n",
            "Epoch 32/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 13866376544487735296.0000\n",
            "Epoch 33/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 13900396533762752512.0000\n",
            "Epoch 34/50\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 13742117436897886208.0000\n",
            "Epoch 35/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 13788733431380705280.0000\n",
            "Epoch 36/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 13650037736118157312.0000\n",
            "Epoch 37/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 13805495486146150400.0000\n",
            "Epoch 38/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: nan\n",
            "Epoch 39/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: nan\n",
            "Epoch 40/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: nan\n",
            "Epoch 1/50\n",
            "133/133 [==============================] - 3s 9ms/step - loss: 16904797763009511424.0000\n",
            "Epoch 2/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 15992991461792546816.0000\n",
            "Epoch 3/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 15902470868501004288.0000\n",
            "Epoch 4/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 15866296935947173888.0000\n",
            "Epoch 5/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 15846670653391372288.0000\n",
            "Epoch 6/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 15836858611625099264.0000\n",
            "Epoch 7/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 15834650792276525056.0000\n",
            "Epoch 8/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 15820308762603814912.0000\n",
            "Epoch 9/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 15764835102447632384.0000\n",
            "Epoch 10/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 15740705220264460288.0000\n",
            "Epoch 11/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 15665161074854854656.0000\n",
            "Epoch 12/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 15416584585558884352.0000\n",
            "Epoch 13/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 14616577726165811200.0000\n",
            "Epoch 14/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 14147660206175158272.0000\n",
            "Epoch 15/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 14075694971113963520.0000\n",
            "Epoch 16/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 14139085114990133248.0000\n",
            "Epoch 17/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 14047423228628959232.0000\n",
            "Epoch 18/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 13981483317287976960.0000\n",
            "Epoch 19/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 13948519958687252480.0000\n",
            "Epoch 20/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 13842775527397523456.0000\n",
            "Epoch 21/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 13792448681170960384.0000\n",
            "Epoch 22/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 13812505972284850176.0000\n",
            "Epoch 23/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 13747555621408866304.0000\n",
            "Epoch 24/50\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 13766506803825213440.0000\n",
            "Epoch 25/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 13645263656630353920.0000\n",
            "Epoch 26/50\n",
            "133/133 [==============================] - 2s 19ms/step - loss: 13616034239517556736.0000\n",
            "Epoch 27/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 13515913810203901952.0000\n",
            "Epoch 28/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 13529589535830179840.0000\n",
            "Epoch 29/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 13424259620424122368.0000\n",
            "Epoch 30/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 13370036104988721152.0000\n",
            "Epoch 31/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 13331782995946766336.0000\n",
            "Epoch 32/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 13275626539069734912.0000\n",
            "Epoch 33/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 13131185895552057344.0000\n",
            "Epoch 34/50\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 13283535326208327680.0000\n",
            "Epoch 35/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 13067309767536410624.0000\n",
            "Epoch 36/50\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 13019098381681688576.0000\n",
            "Epoch 37/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 12996107593544892416.0000\n",
            "Epoch 38/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: nan\n",
            "Epoch 39/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: nan\n",
            "Epoch 40/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: nan\n",
            "Epoch 41/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: nan\n",
            "Epoch 1/50\n",
            "133/133 [==============================] - 3s 11ms/step - loss: 27698472515444670464.0000\n",
            "Epoch 2/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 26728800016769482752.0000\n",
            "Epoch 3/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 26701556317656449024.0000\n",
            "Epoch 4/50\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 26719528934724075520.0000\n",
            "Epoch 5/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 26661797977196068864.0000\n",
            "Epoch 6/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 26713156165329485824.0000\n",
            "Epoch 7/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 26614681704922611712.0000\n",
            "Epoch 8/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 26609795475248775168.0000\n",
            "Epoch 9/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 26585115837251715072.0000\n",
            "Epoch 10/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 26540205185303576576.0000\n",
            "Epoch 11/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 26480495106845573120.0000\n",
            "Epoch 12/50\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 26304762362401390592.0000\n",
            "Epoch 13/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 26193913998135525376.0000\n",
            "Epoch 14/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 25585994019138174976.0000\n",
            "Epoch 15/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 24929042418611781632.0000\n",
            "Epoch 16/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 24910432084800045056.0000\n",
            "Epoch 17/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 24609858591114919936.0000\n",
            "Epoch 18/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 24616009259160698880.0000\n",
            "Epoch 19/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 24485706136152965120.0000\n",
            "Epoch 20/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 24271061675201789952.0000\n",
            "Epoch 21/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 24252488724785397760.0000\n",
            "Epoch 22/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 24331035636450459648.0000\n",
            "Epoch 23/50\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 23936577043892797440.0000\n",
            "Epoch 24/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 23884468988829237248.0000\n",
            "Epoch 25/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 24117882113266548736.0000\n",
            "Epoch 26/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 23851074621670424576.0000\n",
            "Epoch 27/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 23674792121412354048.0000\n",
            "Epoch 28/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 23579007066447020032.0000\n",
            "Epoch 29/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 23538665984823918592.0000\n",
            "Epoch 30/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 23504611910688440320.0000\n",
            "Epoch 31/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 23485643136086048768.0000\n",
            "Epoch 32/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: nan\n",
            "Epoch 33/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: nan\n",
            "Epoch 34/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: nan\n",
            "Epoch 35/50\n",
            "133/133 [==============================] - 2s 14ms/step - loss: nan\n",
            "Epoch 1/50\n",
            "133/133 [==============================] - 3s 9ms/step - loss: 464102930371313664.0000\n",
            "Epoch 2/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 441597129941581824.0000\n",
            "Epoch 3/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 440477105550000128.0000\n",
            "Epoch 4/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 439501770016686080.0000\n",
            "Epoch 5/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 439652162591522816.0000\n",
            "Epoch 6/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 438818870216622080.0000\n",
            "Epoch 7/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 437542612094681088.0000\n",
            "Epoch 8/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 436678705192894464.0000\n",
            "Epoch 9/50\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 433327496830648320.0000\n",
            "Epoch 10/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 421466652584968192.0000\n",
            "Epoch 11/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 395877718471737344.0000\n",
            "Epoch 12/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 377678086612713472.0000\n",
            "Epoch 13/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 385898138621181952.0000\n",
            "Epoch 14/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 376168491507515392.0000\n",
            "Epoch 15/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 372053294362656768.0000\n",
            "Epoch 16/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 371939941585780736.0000\n",
            "Epoch 17/50\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 372789039440330752.0000\n",
            "Epoch 18/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 375354543665315840.0000\n",
            "Epoch 19/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 373172356681564160.0000\n",
            "Epoch 20/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 367846665954000896.0000\n",
            "Epoch 21/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 365296692330758144.0000\n",
            "Epoch 22/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 368831965811441664.0000\n",
            "Epoch 23/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 367638720817397760.0000\n",
            "Epoch 24/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 363262492740157440.0000\n",
            "Epoch 25/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 370375645777100800.0000\n",
            "Epoch 26/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 363844100031512576.0000\n",
            "Epoch 27/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 360864835837100032.0000\n",
            "Epoch 28/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 361580686626258944.0000\n",
            "Epoch 29/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 357847638491529216.0000\n",
            "Epoch 30/50\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 358417254234193920.0000\n",
            "Epoch 31/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 354405686060253184.0000\n",
            "Epoch 32/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 352986422707224576.0000\n",
            "Epoch 33/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 357603203312779264.0000\n",
            "Epoch 34/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 349406653365354496.0000\n",
            "Epoch 35/50\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 347126266249347072.0000\n",
            "Epoch 36/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 350979917065748480.0000\n",
            "Epoch 37/50\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 346931274734108672.0000\n",
            "Epoch 38/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 343768632616026112.0000\n",
            "Epoch 39/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 340005485350486016.0000\n",
            "Epoch 40/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 339451846886162432.0000\n",
            "Epoch 41/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 327037982651449344.0000\n",
            "Epoch 42/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 328419862609133568.0000\n",
            "Epoch 43/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 308927548673228800.0000\n",
            "Epoch 44/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 308983177089646592.0000\n",
            "Epoch 45/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 285917467543339008.0000\n",
            "Epoch 46/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 347911042673672192.0000\n",
            "Epoch 47/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 327539119435546624.0000\n",
            "Epoch 48/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 318947432496889856.0000\n",
            "Epoch 49/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 304706867131580416.0000\n",
            "Epoch 1/50\n",
            "133/133 [==============================] - 3s 9ms/step - loss: 314077695497469952.0000\n",
            "Epoch 2/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 294806795715608576.0000\n",
            "Epoch 3/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 293676154164871168.0000\n",
            "Epoch 4/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 292895191671504896.0000\n",
            "Epoch 5/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 291961603220307968.0000\n",
            "Epoch 6/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 290989841099784192.0000\n",
            "Epoch 7/50\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 289668915317964800.0000\n",
            "Epoch 8/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 285891268242833408.0000\n",
            "Epoch 9/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 265383572498546688.0000\n",
            "Epoch 10/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 245932387169468416.0000\n",
            "Epoch 11/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 242304514193883136.0000\n",
            "Epoch 12/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 242896223248318464.0000\n",
            "Epoch 13/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 237895747444408320.0000\n",
            "Epoch 14/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 233311814748733440.0000\n",
            "Epoch 15/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 233011940132126720.0000\n",
            "Epoch 16/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 229801744136142848.0000\n",
            "Epoch 17/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 226781076456996864.0000\n",
            "Epoch 18/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 226284268999933952.0000\n",
            "Epoch 19/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 224690440996126720.0000\n",
            "Epoch 20/50\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 227258161424236544.0000\n",
            "Epoch 21/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 230875726478311424.0000\n",
            "Epoch 22/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 222568520993472512.0000\n",
            "Epoch 23/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 223467766886170624.0000\n",
            "Epoch 24/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 219803919264514048.0000\n",
            "Epoch 25/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 218075486985650176.0000\n",
            "Epoch 26/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 217059692860407808.0000\n",
            "Epoch 27/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 217857989841780736.0000\n",
            "Epoch 28/50\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 219186972982247424.0000\n",
            "Epoch 29/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 213846060890587136.0000\n",
            "Epoch 30/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 216850837190737920.0000\n",
            "Epoch 31/50\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 216478635324866560.0000\n",
            "Epoch 32/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 211483691438833664.0000\n",
            "Epoch 33/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 215232081196744704.0000\n",
            "Epoch 34/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 209061501682581504.0000\n",
            "Epoch 35/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 208663392573980672.0000\n",
            "Epoch 36/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 210744493207453696.0000\n",
            "Epoch 37/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 211690330905378816.0000\n",
            "Epoch 38/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 208516092375597056.0000\n",
            "Epoch 39/50\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 207435444244185088.0000\n",
            "Epoch 40/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 211139235061694464.0000\n",
            "Epoch 41/50\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 201430461489086464.0000\n",
            "Epoch 42/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 201101690332512256.0000\n",
            "Epoch 43/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 200892525425197056.0000\n",
            "Epoch 44/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 197546625642528768.0000\n",
            "Epoch 45/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 201502376421490688.0000\n",
            "Epoch 46/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 192842674380734464.0000\n",
            "Epoch 47/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 198010069793636352.0000\n",
            "Epoch 48/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 193679041952219136.0000\n",
            "Epoch 49/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 194863490853240832.0000\n",
            "Epoch 50/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 196713487886450688.0000\n",
            "24/24 [==============================] - 0s 5ms/step\n",
            "24/24 [==============================] - 0s 4ms/step\n",
            "24/24 [==============================] - 0s 5ms/step\n",
            "24/24 [==============================] - 0s 6ms/step\n",
            "24/24 [==============================] - 0s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "# Define the TensorFlow model architecture\n",
        "def create_model(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(512, activation='relu', input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "    return model\n",
        "\n",
        "# Define the input shape based on the number of features\n",
        "input_shape = (X_train.shape[1],)\n",
        "\n",
        "\n",
        "# Train each network separately for each label\n",
        "models = []\n",
        "for label_index in range(y_train.shape[1]):\n",
        "    model = create_model(input_shape)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    # Define early stopping callback.\n",
        "    early_stopping = EarlyStopping(monitor='loss', patience=4, restore_best_weights=True)\n",
        "\n",
        "\n",
        "    model.fit(X_train, y_train[:, label_index], epochs=50, batch_size=32, verbose=1, callbacks=[early_stopping])\n",
        "    models.append(model)\n",
        "\n",
        "# Generate predictions for each test data using each trained network\n",
        "predictions = [model.predict(X_test) for model in models]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NfHc3VONVNLq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NfHc3VONVNLq",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "70686a17-68f3-4cb8-a49a-78ace94bf11a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1.9010698e+09],\n",
              "        [1.8041412e+09],\n",
              "        [1.5063369e+09],\n",
              "        [5.4741228e+09],\n",
              "        [7.1684792e+09]],\n",
              "\n",
              "       [[5.2280643e+08],\n",
              "        [5.1752858e+08],\n",
              "        [5.1708973e+08],\n",
              "        [4.1295214e+09],\n",
              "        [5.5027876e+09]],\n",
              "\n",
              "       [[4.9643990e+08],\n",
              "        [4.8595632e+08],\n",
              "        [4.6521878e+08],\n",
              "        [2.7194813e+09],\n",
              "        [4.2447017e+09]],\n",
              "\n",
              "       [[6.2170424e+07],\n",
              "        [5.7167584e+07],\n",
              "        [5.6370792e+07],\n",
              "        [1.1084889e+08],\n",
              "        [1.6599034e+08]],\n",
              "\n",
              "       [[6.2907244e+07],\n",
              "        [6.4461312e+07],\n",
              "        [6.2854012e+07],\n",
              "        [4.6123901e+08],\n",
              "        [7.4923162e+08]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert the list of predictions into a NumPy array\n",
        "predictions_array = np.array(predictions)\n",
        "\n",
        "# Now you can use NumPy array slicing\n",
        "predictions_array[:, :5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oJ_mmT9hUZQH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "collapsed": true,
        "id": "oJ_mmT9hUZQH",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "e4884368-f8ff-4344-fd2c-ad5a19d9a339"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Export Value of Fruits and Vegetables (USD)  \\\n",
              "0                                 1.901070e+09   \n",
              "1                                 1.804141e+09   \n",
              "2                                 1.506337e+09   \n",
              "3                                 5.474123e+09   \n",
              "4                                 7.168479e+09   \n",
              "\n",
              "   Export Value of Non-food Items (USD)  \\\n",
              "0                          5.228064e+08   \n",
              "1                          5.175286e+08   \n",
              "2                          5.170897e+08   \n",
              "3                          4.129521e+09   \n",
              "4                          5.502788e+09   \n",
              "\n",
              "   Export Value of Other food Items (USD)  \\\n",
              "0                            4.964399e+08   \n",
              "1                            4.859563e+08   \n",
              "2                            4.652188e+08   \n",
              "3                            2.719481e+09   \n",
              "4                            4.244702e+09   \n",
              "\n",
              "   Export Value of Sugar and Honey Items (USD)  Export Value of Tobacco (USD)  \n",
              "0                                   62170424.0                     62907244.0  \n",
              "1                                   57167584.0                     64461312.0  \n",
              "2                                   56370792.0                     62854012.0  \n",
              "3                                  110848888.0                    461239008.0  \n",
              "4                                  165990336.0                    749231616.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4efc6fa3-3541-4b41-8378-0e729c0c6c87\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Export Value of Fruits and Vegetables (USD)</th>\n",
              "      <th>Export Value of Non-food Items (USD)</th>\n",
              "      <th>Export Value of Other food Items (USD)</th>\n",
              "      <th>Export Value of Sugar and Honey Items (USD)</th>\n",
              "      <th>Export Value of Tobacco (USD)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.901070e+09</td>\n",
              "      <td>5.228064e+08</td>\n",
              "      <td>4.964399e+08</td>\n",
              "      <td>62170424.0</td>\n",
              "      <td>62907244.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.804141e+09</td>\n",
              "      <td>5.175286e+08</td>\n",
              "      <td>4.859563e+08</td>\n",
              "      <td>57167584.0</td>\n",
              "      <td>64461312.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.506337e+09</td>\n",
              "      <td>5.170897e+08</td>\n",
              "      <td>4.652188e+08</td>\n",
              "      <td>56370792.0</td>\n",
              "      <td>62854012.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.474123e+09</td>\n",
              "      <td>4.129521e+09</td>\n",
              "      <td>2.719481e+09</td>\n",
              "      <td>110848888.0</td>\n",
              "      <td>461239008.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.168479e+09</td>\n",
              "      <td>5.502788e+09</td>\n",
              "      <td>4.244702e+09</td>\n",
              "      <td>165990336.0</td>\n",
              "      <td>749231616.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4efc6fa3-3541-4b41-8378-0e729c0c6c87')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4efc6fa3-3541-4b41-8378-0e729c0c6c87 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4efc6fa3-3541-4b41-8378-0e729c0c6c87');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7faab488-0b1a-42ca-8adc-7ba20be15c8f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7faab488-0b1a-42ca-8adc-7ba20be15c8f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7faab488-0b1a-42ca-8adc-7ba20be15c8f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "predictions_df",
              "summary": "{\n  \"name\": \"predictions_df\",\n  \"rows\": 750,\n  \"fields\": [\n    {\n      \"column\": \"Export Value of Fruits and Vegetables (USD)\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 750,\n        \"samples\": [\n          2819512576.0,\n          439319040.0,\n          1684041984.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Export Value of Non-food Items (USD)\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 750,\n        \"samples\": [\n          578682176.0,\n          352933472.0,\n          1239385088.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Export Value of Other food Items (USD)\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 750,\n        \"samples\": [\n          542028160.0,\n          325165952.0,\n          557091584.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Export Value of Sugar and Honey Items (USD)\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 750,\n        \"samples\": [\n          90876984.0,\n          39313140.0,\n          95972536.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Export Value of Tobacco (USD)\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 750,\n        \"samples\": [\n          99874656.0,\n          50142784.0,\n          79741584.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "target_columns = ['Export Value of Fruits and Vegetables (USD)',\n",
        "                  'Export Value of Non-food Items (USD)',\n",
        "                  'Export Value of Other food Items (USD)',\n",
        "                  'Export Value of Sugar and Honey Items (USD)',\n",
        "                  'Export Value of Tobacco (USD)']\n",
        "\n",
        "# Concatenate the predictions into one DataFrame\n",
        "predictions_df = pd.DataFrame(np.concatenate(predictions, axis=1), columns=target_columns)\n",
        "\n",
        "predictions_df.head()  # Display the concatenated predictions DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SOFJG02m7P75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOFJG02m7P75",
        "outputId": "498954aa-9805-42a3-9c63-c5b4005d1098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 1090506500.0\n",
            "Mean Squared Error (MSE): 5.0889994e+18\n",
            "Root Mean Squared Error (RMSE): 1938827500.0\n",
            "Mean R-squared (R2): 0.25558493137359617\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Convert predictions_df to NumPy array\n",
        "predictions_array = predictions_df.to_numpy()\n",
        "\n",
        "# Calculate MAE, MSE, RMSE, and R2 for each label\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "rmse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for label_index in range(y_test.shape[1]):\n",
        "    actual_values = y_test[:, label_index]\n",
        "    predicted_values = predictions_array[:, label_index]\n",
        "\n",
        "    mae = mean_absolute_error(actual_values, predicted_values)\n",
        "    mse = mean_squared_error(actual_values, predicted_values)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(actual_values, predicted_values)\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    rmse_scores.append(rmse)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Aggregate the metrics\n",
        "mean_mae = np.mean(mae_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "mean_rmse = np.mean(rmse_scores)\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "\n",
        "# Display or use the aggregated evaluation metrics as needed\n",
        "print(\"Mean Absolute Error (MAE):\", mean_mae)\n",
        "print(\"Mean Squared Error (MSE):\", mean_mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", mean_rmse)\n",
        "print(\"Mean R-squared (R2):\", mean_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KxV6w8xOYuuh",
      "metadata": {
        "id": "KxV6w8xOYuuh"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yDryUVkJaWiB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "yDryUVkJaWiB",
        "outputId": "ca23e4af-b5c8-4ad7-e8a9-899f8c75f105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.12.0\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.7 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.0 requires keras>=3.2.0, but you have keras 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              },
              "id": "8aae4c2da876417187a155006aec269e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#!pip install keras==2.12.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow==2.12.0\n",
        "#!pip install keras==2.12.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p6OHl0ddVw4b",
        "outputId": "08f7e9c1-851f-48e6-e76c-fc76521fa9ad"
      },
      "id": "p6OHl0ddVw4b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.12.1)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.33)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.44.0)\n",
            "Requirement already satisfied: jaxlib<=0.4.33,>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.33)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.35-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.34-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.31-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.30-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp310-cp310-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, numpy, gast, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.33\n",
            "    Uninstalling jaxlib-0.4.33:\n",
            "      Successfully uninstalled jaxlib-0.4.33\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.33\n",
            "    Uninstalling jax-0.4.33:\n",
            "      Successfully uninstalled jax-0.4.33\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.25.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.12.0 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 numpy-1.23.5 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "jax",
                  "jaxlib",
                  "numpy",
                  "tensorflow",
                  "wrapt"
                ]
              },
              "id": "cbd83f60eefc4fcc8d7562627f43c7f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras==2.12.0 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sz4Mm2tn2yg8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sz4Mm2tn2yg8",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "137d0654-1012-46d1-8a11-213634535ed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-4533def08556>:46: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  keras_model = KerasRegressor(build_fn=create_model, input_shape=input_shape, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "67/67 [==============================] - 3s 10ms/step - loss: 21206643603752878080.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19824456332568690688.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19591984390084755456.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19499893694188748800.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19483961770702274560.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19474930382191722496.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19501892606328045568.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19493070125026770944.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19443484349637328896.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19452876377961791488.0000\n",
            "Epoch 11/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19450976421868994560.0000\n",
            "Epoch 12/40\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 19442688303218819072.0000\n",
            "Epoch 13/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 19425324815592980480.0000\n",
            "Epoch 14/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 19387998594853240832.0000\n",
            "Epoch 15/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 19454721358473199616.0000\n",
            "Epoch 16/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 19392807858713133056.0000\n",
            "Epoch 17/40\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 19365210116855955456.0000\n",
            "Epoch 18/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19341487053975060480.0000\n",
            "Epoch 19/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19316429183978045440.0000\n",
            "Epoch 20/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19345214398393221120.0000\n",
            "Epoch 21/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19325915770302496768.0000\n",
            "Epoch 22/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19253713040729702400.0000\n",
            "Epoch 23/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19148003793812062208.0000\n",
            "Epoch 24/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19172327190041722880.0000\n",
            "Epoch 25/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 18985311257273303040.0000\n",
            "Epoch 26/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 18803711518783307776.0000\n",
            "Epoch 27/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 18527674726583631872.0000\n",
            "Epoch 28/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 17694372456078245888.0000\n",
            "Epoch 29/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 17363737214978097152.0000\n",
            "Epoch 30/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 17513613843983499264.0000\n",
            "Epoch 31/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 17213897969368039424.0000\n",
            "Epoch 32/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 16943583035679309824.0000\n",
            "Epoch 33/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 17222645683878625280.0000\n",
            "Epoch 34/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 16966459474606817280.0000\n",
            "Epoch 35/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 16966281353723117568.0000\n",
            "67/67 [==============================] - 1s 5ms/step - loss: 15183855357354049536.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 4s 11ms/step - loss: 15745267094008102912.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14466283282741854208.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14401599013679792128.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14361023736079974400.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14364344261195857920.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14356051744499171328.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14438481031721910272.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14337062079175852032.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 14300824374947610624.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 14305889825016774656.0000\n",
            "Epoch 11/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 14331080735920750592.0000\n",
            "Epoch 12/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 14282601069228851200.0000\n",
            "Epoch 13/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 14318020736806027264.0000\n",
            "Epoch 14/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 14213372518609190912.0000\n",
            "Epoch 15/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14193869381355700224.0000\n",
            "Epoch 16/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14116030555178926080.0000\n",
            "Epoch 17/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14044078514257264640.0000\n",
            "Epoch 18/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 13979859338613751808.0000\n",
            "Epoch 19/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 13353087133246554112.0000\n",
            "Epoch 20/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12349215424901021696.0000\n",
            "Epoch 21/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 12208576892592193536.0000\n",
            "Epoch 22/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 12002542707198132224.0000\n",
            "Epoch 23/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 11985153930804854784.0000\n",
            "Epoch 24/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: nan\n",
            "Epoch 25/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: nan\n",
            "Epoch 26/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: nan\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 18581755305507422208.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 3s 15ms/step - loss: 20797304220824895488.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 19536817493672722432.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 19482092600935055360.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 19540967050555949056.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 8ms/step - loss: 19482664346981498880.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19456454188798574592.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19482730317679165440.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19494534674514968576.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19399380739223977984.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19485395533864894464.0000\n",
            "Epoch 11/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19477604394470473728.0000\n",
            "Epoch 12/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19442655317869985792.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 14594678753075396608.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 2s 9ms/step - loss: 15298105610596253696.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14399951945261383680.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14391668224657719296.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 14392727054355267584.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 14361522914358984704.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 14349242468988354560.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 14387409816123342848.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 14351989049034539008.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 14341217133617217536.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14320372592177840128.0000\n",
            "Epoch 11/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14315025667131965440.0000\n",
            "Epoch 12/40\n",
            "67/67 [==============================] - 1s 8ms/step - loss: 14332423239618265088.0000\n",
            "Epoch 13/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14286877069949272064.0000\n",
            "Epoch 14/40\n",
            "67/67 [==============================] - 1s 8ms/step - loss: 14288696761693241344.0000\n",
            "Epoch 15/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14233245091769614336.0000\n",
            "Epoch 16/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14269823644602466304.0000\n",
            "Epoch 17/40\n",
            "67/67 [==============================] - 1s 8ms/step - loss: 14235760774373965824.0000\n",
            "Epoch 18/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14189576887960862720.0000\n",
            "Epoch 19/40\n",
            "67/67 [==============================] - 1s 8ms/step - loss: 14197354833215750144.0000\n",
            "Epoch 20/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14118115229225189376.0000\n",
            "Epoch 21/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14087886356042743808.0000\n",
            "Epoch 22/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14005457068820004864.0000\n",
            "Epoch 23/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 13894428384647184384.0000\n",
            "Epoch 24/40\n",
            "67/67 [==============================] - 1s 8ms/step - loss: 13625724235493146624.0000\n",
            "Epoch 25/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 13037884637353869312.0000\n",
            "Epoch 26/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 12393397100639944704.0000\n",
            "Epoch 27/40\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 12084535488304644096.0000\n",
            "Epoch 28/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 12064643123934920704.0000\n",
            "Epoch 29/40\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 12136073996345016320.0000\n",
            "Epoch 30/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 12117550523951874048.0000\n",
            "Epoch 31/40\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 11999246371338059776.0000\n",
            "Epoch 32/40\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 12126504946648481792.0000\n",
            "Epoch 33/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11963406690319073280.0000\n",
            "Epoch 34/40\n",
            "67/67 [==============================] - 1s 8ms/step - loss: 12019489479917043712.0000\n",
            "Epoch 35/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11980152252410101760.0000\n",
            "Epoch 36/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11941439547507736576.0000\n",
            "Epoch 37/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11938648986996441088.0000\n",
            "Epoch 38/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11996062185664020480.0000\n",
            "Epoch 39/40\n",
            "67/67 [==============================] - 1s 8ms/step - loss: 11913349224441315328.0000\n",
            "Epoch 40/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11942484083554123776.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 17762798363209629696.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 10ms/step - loss: 21186529138034343936.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19555122163251937280.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19488793024794722304.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19469921007215575040.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 19469138154936598528.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 19522475464000012288.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 19473395463959347200.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 19496384053072887808.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 14352719124755382272.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 10ms/step - loss: 15766503061586968576.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14600267570679382016.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14402458831772712960.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14384474120077180928.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14371399827311296512.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14347973632569901056.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14328082367711805440.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 14305398343319158784.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 14310666103527833600.0000\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 14305945900109791232.0000\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 14260876918487252992.0000\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 14250150083046670336.0000\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 14339320476059303936.0000\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14253869730883436544.0000\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 14179758249124823040.0000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 14128960811921571840.0000\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 14045901504536117248.0000\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 13887501461392195584.0000\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 13572519967336693760.0000\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 3s 40ms/step - loss: 12528102668205293568.0000\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 12479146912978567168.0000\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 12103249176209391616.0000\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 11972471064178458624.0000\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 11825998523172651008.0000\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 11822825332614889472.0000\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 11725764844161335296.0000\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: nan\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: nan\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: nan\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 17787963985346166784.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 10ms/step - loss: 20553751400156233728.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19498169659956396032.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19521171443209469952.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19513696963163848704.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19497701268002963456.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19496155354654310400.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19479689068516737024.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19518921842419040256.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19475225051307966464.0000\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19468799505355243520.0000\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19469714299029553152.0000\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 19469584556657475584.0000\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 19452185884659548160.0000\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 19424517774058192896.0000\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 19390021696248348672.0000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 19416539717687050240.0000\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 19426002114755690496.0000\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 19404601220432658432.0000\n",
            "67/67 [==============================] - 1s 6ms/step - loss: 14307630351923544064.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 9ms/step - loss: 15403082582769795072.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14412405013957574656.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14394537950006214656.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14383966145705148416.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14386563192169955328.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14341818566477611008.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14350504708337041408.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14355075378173706240.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 14347598699104829440.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 19559583981437452288.0000\n",
            "Epoch 1/50\n",
            "133/133 [==============================] - 4s 15ms/step - loss: 17813077930436198400.0000\n",
            "Epoch 2/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 16934284465843208192.0000\n",
            "Epoch 3/50\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 16926043626193027072.0000\n",
            "Epoch 4/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 16955214769189552128.0000\n",
            "Epoch 5/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 16963821746211782656.0000\n",
            "Epoch 6/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 16890334787057745920.0000\n",
            "Epoch 7/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 16851736431364669440.0000\n",
            "Epoch 8/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 16819550427484782592.0000\n",
            "Epoch 9/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 16790283626976641024.0000\n",
            "Epoch 10/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 16751557727934742528.0000\n",
            "Epoch 11/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 16646770971272806400.0000\n",
            "Epoch 12/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 16390441825489387520.0000\n",
            "Epoch 13/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 15470550815273385984.0000\n",
            "Epoch 14/50\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 15137006266406141952.0000\n",
            "Epoch 15/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 14917041268688158720.0000\n",
            "Epoch 16/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 14662210757253398528.0000\n",
            "Epoch 17/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 14567060120497291264.0000\n",
            "Epoch 18/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 14538383757733265408.0000\n",
            "Epoch 19/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 14557693380940267520.0000\n",
            "Epoch 20/50\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 14450940697487867904.0000\n",
            "Epoch 21/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 14470508705927397376.0000\n",
            "Epoch 22/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 14433513438187618304.0000\n",
            "Epoch 23/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 14310438504620883968.0000\n",
            "Epoch 24/50\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 14184289336542887936.0000\n",
            "Epoch 25/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 14222425897352298496.0000\n",
            "Epoch 26/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 14256638301162176512.0000\n",
            "Epoch 27/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 14235746480722804736.0000\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 3s 11ms/step - loss: 20739379749250400256.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19074026452472037376.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 18933183411000442880.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 18932196049558700032.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 18910188224817135616.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 18893202969191251968.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 18894513587051560960.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 18990366811737817088.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 18904620297934077952.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 12854905011771015168.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 3s 10ms/step - loss: 14376502660775804928.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 13097501257323511808.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12919452941391233024.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12946673550760083456.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 12895969572045193216.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12907757436206579712.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12791060769592573952.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12915764079880044544.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12811900912985440256.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12830645387215765504.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 18928349957884739584.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 2s 9ms/step - loss: 20374722319851978752.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 18969177023647318016.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18956952653369704448.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18894966585842204672.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 18903138156259835904.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18949000985277628416.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18924923879652589568.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 12908720608392511488.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 2s 10ms/step - loss: 13686200673555709952.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12931204521668902912.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 12890048701929619456.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 12908772285439016960.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 12880188281651724288.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 12898872282742521856.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 12884691881279094784.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 12866273962002219008.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 12861691197537648640.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 12843677898539794432.0000\n",
            "Epoch 11/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 12835181972191969280.0000\n",
            "Epoch 12/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 12790434047964741632.0000\n",
            "Epoch 13/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12808146080776585216.0000\n",
            "Epoch 14/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12816704679287193600.0000\n",
            "Epoch 15/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 12803829398125936640.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 18991692822760914944.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 10ms/step - loss: 20760334241852555264.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 19331037295464677376.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18929682565977604096.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 18915081051560738816.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 18894414631005061120.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 19008557132107743232.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 18890146326866034688.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 18926687496303542272.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 18910271787700846592.0000\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 18877979131193065472.0000\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 18858557357800030208.0000\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 18873363381379661824.0000\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 18863977950124965888.0000\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18846497914266583040.0000\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18839700733383671808.0000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18915230585142116352.0000\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18848239540684980224.0000\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18790763669854617600.0000\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 18759414394323468288.0000\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 18780547007809323008.0000\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18722431221211594752.0000\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18696460756563525632.0000\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 18677030187077468160.0000\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 18657713966800699392.0000\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 18548382928581165056.0000\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 18448171239802404864.0000\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 18169318598323994624.0000\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 17545423814886686720.0000\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 16827455916088492032.0000\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 16713996211706658816.0000\n",
            "Epoch 31/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 16678569947059716096.0000\n",
            "Epoch 32/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 16532307412774813696.0000\n",
            "Epoch 33/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 16293003105035878400.0000\n",
            "Epoch 34/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 16191820547489792000.0000\n",
            "Epoch 35/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 16140409582798241792.0000\n",
            "Epoch 36/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 16132142354868994048.0000\n",
            "Epoch 37/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: nan\n",
            "Epoch 38/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: nan\n",
            "Epoch 39/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: nan\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 12377925872525508608.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 10ms/step - loss: 14396349945168789504.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 13016565106891292672.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 12921611282716557312.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 12893087752068792320.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 12865161256234909696.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 12850218893213433856.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 12856886331724267520.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12875579128908087296.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12827019197867360256.0000\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12817672249519636480.0000\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12793099264150470656.0000\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12782747362174959616.0000\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 12748642710504603648.0000\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 12732614029994885120.0000\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12694993140138901504.0000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12658350815631638528.0000\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 12539064799134220288.0000\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12450842185144729600.0000\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12100108971000463360.0000\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 11460195402658086912.0000\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 11224996671337267200.0000\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 11106196638979325952.0000\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 11065574082379513856.0000\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 11054240316520398848.0000\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 11053435474008866816.0000\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 10994090433411284992.0000\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 10950104470742106112.0000\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 10972298112948764672.0000\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11046473366381789184.0000\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 10980226691296657408.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 17348892708491493376.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 9ms/step - loss: 20421513136683614208.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 18913495555793485824.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 18958685483695079424.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 18940868997278597120.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 18920521435094974464.0000\n",
            "67/67 [==============================] - 1s 5ms/step - loss: 13006455097473892352.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 3s 17ms/step - loss: 13884023706113540096.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 12892741405906042880.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 12893529755743158272.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 12883260317139730432.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12888209218976350208.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 12885980508906848256.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12879454907395997696.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12854350857910616064.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 12857927569235771392.0000\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12839446977796112384.0000\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12825734968286117888.0000\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 12822275904705134592.0000\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12813862441729392640.0000\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 12802318669149372416.0000\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 12754464624573677568.0000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12763110084502880256.0000\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 12719692569345261568.0000\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 12698137743394340864.0000\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 12651996737934721024.0000\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 12592940868895244288.0000\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 12526318160833413120.0000\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 12363724580341153792.0000\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 12087599827211255808.0000\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 11597178058804559872.0000\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 11224719594407067648.0000\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 11160557593368199168.0000\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11161094155042553856.0000\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11108681535258099712.0000\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11104766174351589376.0000\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11131988982743695360.0000\n",
            "Epoch 31/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11101609476468244480.0000\n",
            "Epoch 32/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11045137459754041344.0000\n",
            "Epoch 33/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 11081290501586944000.0000\n",
            "Epoch 34/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 11090123978004496384.0000\n",
            "Epoch 35/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 11008033340363112448.0000\n",
            "Epoch 36/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11031381469778935808.0000\n",
            "Epoch 37/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 11053766427008827392.0000\n",
            "Epoch 38/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 11038170954080452608.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 17096444838754123776.0000\n",
            "Epoch 1/50\n",
            "133/133 [==============================] - 4s 17ms/step - loss: 16926573590797615104.0000\n",
            "Epoch 2/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 15935605750915661824.0000\n",
            "Epoch 3/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 15886770941967990784.0000\n",
            "Epoch 4/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 15890799552572162048.0000\n",
            "Epoch 5/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 15866768626435489792.0000\n",
            "Epoch 6/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 15882641176294064128.0000\n",
            "Epoch 7/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 15809346631674888192.0000\n",
            "Epoch 8/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 15792535098886193152.0000\n",
            "Epoch 9/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 15800234978815508480.0000\n",
            "Epoch 10/50\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 15758122583960059904.0000\n",
            "Epoch 11/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 15682718076527181824.0000\n",
            "Epoch 12/50\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 15511422961012703232.0000\n",
            "Epoch 13/50\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 14903427115713036288.0000\n",
            "Epoch 14/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 14340660780733562880.0000\n",
            "Epoch 15/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 14166298027777589248.0000\n",
            "Epoch 16/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 14113329055109480448.0000\n",
            "Epoch 17/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 14086182113019691008.0000\n",
            "Epoch 18/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 13973318343940112384.0000\n",
            "Epoch 19/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 13895818167344693248.0000\n",
            "Epoch 20/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 13902506496576454656.0000\n",
            "Epoch 21/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 13751334642873532416.0000\n",
            "Epoch 22/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 13738232862316953600.0000\n",
            "Epoch 23/50\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 13762191220686192640.0000\n",
            "Epoch 24/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 13677761921812529152.0000\n",
            "Epoch 25/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 13766866344127496192.0000\n",
            "Epoch 26/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 13615075465378136064.0000\n",
            "Epoch 27/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 13532672566434463744.0000\n",
            "Epoch 28/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 13561608413942644736.0000\n",
            "Epoch 29/50\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 13619820957563617280.0000\n",
            "Epoch 30/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 13369378597035311104.0000\n",
            "Epoch 31/50\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 13453251543025319936.0000\n",
            "Epoch 32/50\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 13456165248838926336.0000\n",
            "Epoch 33/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 13372714515313983488.0000\n",
            "24/24 [==============================] - 0s 5ms/step\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 4s 13ms/step - loss: 32895703451244167168.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 30794543327633997824.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30600321195657134080.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30673487097415860224.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 30558880602406256640.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 30646518276209770496.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 30580134162171166720.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30553156544872054784.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 30517538965201879040.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 30507185963714740224.0000\n",
            "Epoch 11/40\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 30500298622878351360.0000\n",
            "Epoch 12/40\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 30535364247711383552.0000\n",
            "Epoch 13/40\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 30526381237712453632.0000\n",
            "Epoch 14/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 30517831435294867456.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 22778481237565636608.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 3s 11ms/step - loss: 24997163761022271488.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 23555479716635869184.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22923150579501891584.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22905173564387753984.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22889140485831524352.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 22877749545367764992.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 22859319531462983680.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22811365431329161216.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22791143213471105024.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 22799316982911991808.0000\n",
            "Epoch 11/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 22766058955195023360.0000\n",
            "Epoch 12/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 22873560406065938432.0000\n",
            "Epoch 13/40\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 22756508597196161024.0000\n",
            "Epoch 14/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 22745713592034656256.0000\n",
            "Epoch 15/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22784013980076605440.0000\n",
            "Epoch 16/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22735949928780005376.0000\n",
            "Epoch 17/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22704224620272156672.0000\n",
            "Epoch 18/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22656820275952222208.0000\n",
            "Epoch 19/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 22719188973526188032.0000\n",
            "Epoch 20/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22685864975111553024.0000\n",
            "Epoch 21/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 22624393479025852416.0000\n",
            "Epoch 22/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 22629811872327532544.0000\n",
            "Epoch 23/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22556821892429250560.0000\n",
            "Epoch 24/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22513826589736697856.0000\n",
            "Epoch 25/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22411286135330308096.0000\n",
            "Epoch 26/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22342964681803563008.0000\n",
            "Epoch 27/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 22157481468244262912.0000\n",
            "Epoch 28/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 21877088410975338496.0000\n",
            "Epoch 29/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 21490902543905062912.0000\n",
            "Epoch 30/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 21445870945677869056.0000\n",
            "Epoch 31/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 21205946513380868096.0000\n",
            "Epoch 32/40\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 21152228773294243840.0000\n",
            "Epoch 33/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 21034501864285011968.0000\n",
            "Epoch 34/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 20934631024110862336.0000\n",
            "Epoch 35/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 21118194490368065536.0000\n",
            "Epoch 36/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 21043102244237475840.0000\n",
            "Epoch 37/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 21025178005681471488.0000\n",
            "67/67 [==============================] - 1s 5ms/step - loss: 28495400742279970816.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 2s 11ms/step - loss: 32179982954213146624.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30612338857748725760.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30636671050071408640.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30601647206680231936.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30595901158913474560.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30596314575285518336.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30583729565193994240.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30586443159891345408.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30575879052171673600.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30544934396919545856.0000\n",
            "Epoch 11/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30609082104307253248.0000\n",
            "Epoch 12/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30544241704594046976.0000\n",
            "Epoch 13/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30553354456965054464.0000\n",
            "Epoch 14/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30534500031571951616.0000\n",
            "Epoch 15/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 30541512716733906944.0000\n",
            "Epoch 16/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 30526381237712453632.0000\n",
            "Epoch 17/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 30512694516969897984.0000\n",
            "Epoch 18/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 30469092283858812928.0000\n",
            "Epoch 19/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 30465338551161585664.0000\n",
            "Epoch 20/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 30487326584693850112.0000\n",
            "Epoch 21/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 30443594609210687488.0000\n",
            "Epoch 22/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30446147675210383360.0000\n",
            "Epoch 23/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30475368296230158336.0000\n",
            "Epoch 24/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30397014898611585024.0000\n",
            "Epoch 25/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30381531575869243392.0000\n",
            "Epoch 26/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30415787960144232448.0000\n",
            "Epoch 27/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30373159894335356928.0000\n",
            "Epoch 28/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30371897654986670080.0000\n",
            "Epoch 29/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30352161421268090880.0000\n",
            "Epoch 30/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30299398057274376192.0000\n",
            "Epoch 31/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30241521964211503104.0000\n",
            "Epoch 32/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30205523953518116864.0000\n",
            "Epoch 33/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30139183819944624128.0000\n",
            "Epoch 34/40\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 30068067407860072448.0000\n",
            "Epoch 35/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 29902157700298440704.0000\n",
            "Epoch 36/40\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 29623495274331635712.0000\n",
            "Epoch 37/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 29199088184056610816.0000\n",
            "Epoch 38/40\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 28599179246779236352.0000\n",
            "Epoch 39/40\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 27941306255508766720.0000\n",
            "Epoch 40/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 27707846951583088640.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 21194973387335663616.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 2s 10ms/step - loss: 24203551661256343552.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 22880546702948827136.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22855853870812233728.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22870033172764033024.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 22803840373748662272.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 22873015048298561536.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 22844139673929908224.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 22805122404306649088.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 30671061574764986368.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 3s 11ms/step - loss: 32921333067287625728.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 31000376302400176128.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 30602795096819630080.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 30632176246537060352.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 30601295362959343616.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 30626553344072613888.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 30575032428218286080.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 30537294990129758208.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 30525325706549788672.0000\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 30508069971063472128.0000\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 30528446120549416960.0000\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 30550104300593348608.0000\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 30459049344650706944.0000\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 30499948978180718592.0000\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30450785415256342528.0000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30710223979923111936.0000\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 30458409428883341312.0000\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30469294593998323712.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 23438889702649757696.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 3s 10ms/step - loss: 24992277531348434944.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 23320320567733649408.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22950790102800924672.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 22876263005647011840.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 22841432676302323712.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 22816038355747209216.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 22818892687932915712.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 22819471031049125888.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 22780629683286310912.0000\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22823710747885830144.0000\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22774314088496365568.0000\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22736866921477570560.0000\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22742887847151271936.0000\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22744726230592913408.0000\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22736457903152037888.0000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22698685280691421184.0000\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22719173580363399168.0000\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22684187120367566848.0000\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22639146726047350784.0000\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22650572850883198976.0000\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22590990315774017536.0000\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22547449655314087936.0000\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 22478928090671087616.0000\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 22383279375147597824.0000\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 22297209604925292544.0000\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 22069584309696593920.0000\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 21613253998820720640.0000\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 21351724163037921280.0000\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 21182416964546461696.0000\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 21103808480230244352.0000\n",
            "Epoch 31/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 21333487663179628544.0000\n",
            "Epoch 32/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 21111892089717653504.0000\n",
            "Epoch 33/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 20962829099316805632.0000\n",
            "Epoch 34/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 20924702434112045056.0000\n",
            "Epoch 35/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 21207188961520254976.0000\n",
            "Epoch 36/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 20926059231460720640.0000\n",
            "Epoch 37/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 20891640119464820736.0000\n",
            "Epoch 38/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 20888444938674503680.0000\n",
            "Epoch 39/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 20932731068018065408.0000\n",
            "Epoch 41/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 20840167582122115072.0000\n",
            "Epoch 42/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 20706315235579920384.0000\n",
            "Epoch 43/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 20706849598231019520.0000\n",
            "Epoch 44/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 20700863856929406976.0000\n",
            "Epoch 45/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 20644551269401231360.0000\n",
            "Epoch 46/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 20674218292141883392.0000\n",
            "Epoch 47/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 20576854338479063040.0000\n",
            "Epoch 48/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 20579176507036925952.0000\n",
            "Epoch 49/50\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 20591796701500538880.0000\n",
            "Epoch 50/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 20514943037742252032.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 28082131704794316800.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 9ms/step - loss: 32089908762642481152.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30652108193325383680.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 30531689679851356160.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30617086548957462528.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30630003611560574976.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 30610311358307106816.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 22885758388064485376.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 9ms/step - loss: 24549279898470973440.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 22903752995364667392.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 22874838038577414144.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 22862431149369589760.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 22872722578205573120.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 22859033658439761920.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 22858758780532817920.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 22837003843465641984.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22834046157186924544.0000\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22827248976304013312.0000\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22821208259421011968.0000\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 22783336680913895424.0000\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22793799633563811840.0000\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22783437835983650816.0000\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 22753377188080254976.0000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22773872084821999616.0000\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22735655259663761408.0000\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22711756274922422272.0000\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22710571001387679744.0000\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22671388805020254208.0000\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 22681156866321416192.0000\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 22665779096695341056.0000\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 22620158160235659264.0000\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 22610113022004297728.0000\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 22571375028334493696.0000\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 22541336370663653376.0000\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 22444924594070487040.0000\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 2s 32ms/step - loss: 22381526753612922880.0000\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 22260932318278451200.0000\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 22019431186307219456.0000\n",
            "Epoch 31/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 21836800105910370304.0000\n",
            "Epoch 32/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 21529059995435401216.0000\n",
            "Epoch 33/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 21244669113887883264.0000\n",
            "Epoch 34/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 21293271925882093568.0000\n",
            "Epoch 35/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 21233750963424067584.0000\n",
            "Epoch 36/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 21254113918770479104.0000\n",
            "Epoch 37/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 21183709990220726272.0000\n",
            "Epoch 38/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 21139166575156264960.0000\n",
            "Epoch 39/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 21162247523246538752.0000\n",
            "Epoch 40/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 21075729152280100864.0000\n",
            "Epoch 41/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 21116024054414835712.0000\n",
            "Epoch 42/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 21118135116740165632.0000\n",
            "Epoch 43/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 20969846182525272064.0000\n",
            "Epoch 44/50\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 21044837273586106368.0000\n",
            "Epoch 45/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 21071034237629497344.0000\n",
            "Epoch 46/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 21016757945635962880.0000\n",
            "67/67 [==============================] - 1s 6ms/step - loss: 28771985091270279168.0000\n",
            "Epoch 1/40\n",
            "133/133 [==============================] - 4s 13ms/step - loss: 28050217280286490624.0000\n",
            "Epoch 2/40\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 26723051769979469824.0000\n",
            "Epoch 3/40\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 26735289334396616704.0000\n",
            "Epoch 4/40\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 26714737263050227712.0000\n",
            "Epoch 5/40\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 26638367384408162304.0000\n",
            "Epoch 6/40\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 26685470462542086144.0000\n",
            "Epoch 7/40\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 26653819920824926208.0000\n",
            "Epoch 8/40\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 26594936675111010304.0000\n",
            "Epoch 9/40\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 26592961952227524608.0000\n",
            "Epoch 10/40\n",
            "133/133 [==============================] - 2s 16ms/step - loss: 26536515224280760320.0000\n",
            "Epoch 11/40\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 26506980142935441408.0000\n",
            "Epoch 12/40\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 26341855486676041728.0000\n",
            "Epoch 13/40\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 26119584813074612224.0000\n",
            "Epoch 14/40\n",
            "133/133 [==============================] - 1s 10ms/step - loss: nan\n",
            "Epoch 15/40\n",
            "133/133 [==============================] - 1s 11ms/step - loss: nan\n",
            "Epoch 16/40\n",
            "133/133 [==============================] - 1s 10ms/step - loss: nan\n",
            "24/24 [==============================] - 0s 4ms/step\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 3s 11ms/step - loss: 193448436568162304.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 169902377879470080.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 169353755936948224.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 168826574471168000.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 169213241786892288.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 168611224810946560.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 169628994621145088.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 167994501866979328.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 168792558330183680.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 168101463732518912.0000\n",
            "Epoch 11/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 168001579973083136.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 716796987634089984.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 4s 12ms/step - loss: 762376211371393024.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 713702824474574848.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 710052514589835264.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 710879690931306496.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 710124670040408064.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 709408475653865472.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 708821061566726144.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 707839541280505856.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 706649732260298752.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 707499792187523072.0000\n",
            "Epoch 11/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 704461291804164096.0000\n",
            "Epoch 12/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 703112740792696832.0000\n",
            "Epoch 13/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 703685998667628544.0000\n",
            "Epoch 14/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 698801143383326720.0000\n",
            "Epoch 15/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 698708097211826176.0000\n",
            "Epoch 16/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 690872427596480512.0000\n",
            "Epoch 17/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 662546396724854784.0000\n",
            "Epoch 18/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 614889233450008576.0000\n",
            "Epoch 19/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 602184582749487104.0000\n",
            "Epoch 20/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 591914388231815168.0000\n",
            "Epoch 21/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 593238612548517888.0000\n",
            "Epoch 22/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 591765473125728256.0000\n",
            "Epoch 23/40\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 593207276467126272.0000\n",
            "Epoch 24/40\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 581672025102221312.0000\n",
            "Epoch 25/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 587451333095718912.0000\n",
            "Epoch 26/40\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 578879952762437632.0000\n",
            "Epoch 27/40\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 577970794085220352.0000\n",
            "Epoch 28/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 573752483365519360.0000\n",
            "Epoch 29/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 569897629958275072.0000\n",
            "Epoch 30/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 567318931593756672.0000\n",
            "Epoch 31/40\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 560606378746445824.0000\n",
            "Epoch 32/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 563308084974321664.0000\n",
            "Epoch 33/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 567223823837954048.0000\n",
            "Epoch 34/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 560625310962286592.0000\n",
            "67/67 [==============================] - 1s 4ms/step - loss: 203441210558251008.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 2s 11ms/step - loss: 183671424555155456.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 169173762447507456.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 169116794001293312.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 169304827669512192.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 168428293563875328.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 168994009476235264.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 168839493732794368.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 168779999845810176.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 709080133994020864.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 3s 20ms/step - loss: 744787530020290560.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 712422924220366848.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 711585371237908480.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 708167058306629632.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 710343679012765696.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 710584128461864960.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 709081989419892736.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 187909234426380288.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 3s 12ms/step - loss: 196381486914469888.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 169729050179272704.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 169263321105563648.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 168808758946824192.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 168699134201561088.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 168936456914468864.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 168911941241143296.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 168184030183817216.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 168240208356048896.0000\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 167790559639896064.0000\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 167673736529444864.0000\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 167772950273982464.0000\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 167555796727496704.0000\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 166883823324233728.0000\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 166661876594245632.0000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 167000732334030848.0000\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 165307467247386624.0000\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 164367487884853248.0000\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 162381752705220608.0000\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 158013083770421248.0000\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 150975590877364224.0000\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 155132432025124864.0000\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 145638698875092992.0000\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 146124356597055488.0000\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 146169694271832064.0000\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 146974897560616960.0000\n",
            "67/67 [==============================] - 1s 5ms/step - loss: 625295355092664320.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 3s 17ms/step - loss: 760138499050438656.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 714480591512272896.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 711913575458799616.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 713275320609800192.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 711629076825112576.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 708555117191757824.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 708135790944714752.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 709463176357347328.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 705988788333051904.0000\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 705447485014802432.0000\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 705672610020589568.0000\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 703222623235997696.0000\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 698744106217635840.0000\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 694238994761777152.0000\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 676680000224624640.0000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 629957284394434560.0000\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 603400848768237568.0000\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 596895725661454336.0000\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 592683634054397952.0000\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 608616725771976704.0000\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 588131381037498368.0000\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 596020583125221376.0000\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 591779285740552192.0000\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 574579419188822016.0000\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 581538434439446528.0000\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 570438864557047808.0000\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 565560606342512640.0000\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 583602355203735552.0000\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 567724135988330496.0000\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 563005272600084480.0000\n",
            "Epoch 31/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 559103552509706240.0000\n",
            "Epoch 32/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 560108093820633088.0000\n",
            "Epoch 33/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 576235214980775936.0000\n",
            "Epoch 34/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 559624789740748800.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 190577044772356096.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 10ms/step - loss: 187171702642311168.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 168839476552925184.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 169375883608457216.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 168998613681176576.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 169157475931521024.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 720632908825493504.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 10ms/step - loss: 742956568282136576.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 710148721857265664.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 710296881049108480.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 710459127733682176.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 710841551621718016.0000\n",
            "67/67 [==============================] - 1s 5ms/step - loss: 169484511921307648.0000\n",
            "Epoch 1/50\n",
            "133/133 [==============================] - 5s 14ms/step - loss: 461197333455962112.0000\n",
            "Epoch 2/50\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 441302082868215808.0000\n",
            "Epoch 3/50\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 440602724753473536.0000\n",
            "Epoch 4/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 440112961042776064.0000\n",
            "Epoch 5/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 439701262657650688.0000\n",
            "Epoch 6/50\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 438680263032045568.0000\n",
            "Epoch 7/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 437130604471910400.0000\n",
            "Epoch 8/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 435876886338338816.0000\n",
            "Epoch 9/50\n",
            "133/133 [==============================] - 3s 19ms/step - loss: 430332736394231808.0000\n",
            "Epoch 10/50\n",
            "133/133 [==============================] - 3s 19ms/step - loss: 408775264743456768.0000\n",
            "Epoch 11/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 402750112821936128.0000\n",
            "Epoch 12/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 384298177404076032.0000\n",
            "Epoch 13/50\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 383329610739220480.0000\n",
            "Epoch 14/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 376813389436944384.0000\n",
            "Epoch 15/50\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 381023041502576640.0000\n",
            "Epoch 16/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 374439646911791104.0000\n",
            "Epoch 17/50\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 373239976646672384.0000\n",
            "Epoch 18/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 371395614610554880.0000\n",
            "Epoch 19/50\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 372035805255827456.0000\n",
            "Epoch 20/50\n",
            "133/133 [==============================] - 3s 19ms/step - loss: 368743283326713856.0000\n",
            "Epoch 21/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 371101735768293376.0000\n",
            "Epoch 22/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 370647981063405568.0000\n",
            "Epoch 23/50\n",
            "133/133 [==============================] - 1s 11ms/step - loss: 369195972879712256.0000\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 3s 11ms/step - loss: 338367109945884672.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 301640638439358464.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 298741157557436416.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 298344268219547648.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 298608116650475520.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 299251468391677952.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 298746483316883456.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 288757832495398912.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 3s 11ms/step - loss: 322746726207193088.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 292469749391032320.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 289847104921141248.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 289248008522956800.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 288439386440204288.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 288497763635691520.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 288540163552837632.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 287432079170338816.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 287292870690340864.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 286817812947664896.0000\n",
            "Epoch 11/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 285906146009546752.0000\n",
            "Epoch 12/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 285011212264013824.0000\n",
            "Epoch 13/40\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 284459446405431296.0000\n",
            "Epoch 14/40\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 282471529382412288.0000\n",
            "Epoch 15/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 276846634053140480.0000\n",
            "Epoch 16/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 260056026345111552.0000\n",
            "Epoch 17/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 241210276785946624.0000\n",
            "Epoch 18/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 243307526496452608.0000\n",
            "Epoch 19/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 239008590650671104.0000\n",
            "Epoch 20/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 236777269241053184.0000\n",
            "Epoch 21/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 239808038683279360.0000\n",
            "Epoch 22/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 232696930050768896.0000\n",
            "Epoch 23/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 231428746467344384.0000\n",
            "Epoch 24/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 235308424785559552.0000\n",
            "Epoch 25/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 230648711686914048.0000\n",
            "Epoch 26/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 227737153356955648.0000\n",
            "Epoch 27/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 229463987907985408.0000\n",
            "Epoch 28/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 230255086524170240.0000\n",
            "Epoch 29/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 228947921817567232.0000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 246669953313275904.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 2s 10ms/step - loss: 321923466875895808.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 299496968722317312.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 298998030961475584.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 298764281661358080.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 299015416989089792.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 297874123919458304.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 298587191569809408.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 10ms/step - loss: 298390825665036288.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 298066229216673792.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 289610022726402048.0000\n",
            "Epoch 1/40\n",
            "67/67 [==============================] - 3s 12ms/step - loss: 307425375271518208.0000\n",
            "Epoch 2/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 289945167614443520.0000\n",
            "Epoch 3/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 289502648544002048.0000\n",
            "Epoch 4/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 289734782936416256.0000\n",
            "Epoch 5/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 289752684360105984.0000\n",
            "Epoch 6/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 288514015791939584.0000\n",
            "Epoch 7/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 289319579857977344.0000\n",
            "Epoch 8/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 288116301820329984.0000\n",
            "Epoch 9/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 288445846071017472.0000\n",
            "Epoch 10/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 288188800868286464.0000\n",
            "Epoch 11/40\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 288070242591047680.0000\n",
            "Epoch 12/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 287097569937457152.0000\n",
            "Epoch 13/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 286813964656967680.0000\n",
            "Epoch 14/40\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 286188548699193344.0000\n",
            "Epoch 15/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 285477233395499008.0000\n",
            "Epoch 16/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 284053056599883776.0000\n",
            "Epoch 17/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 282906764188319744.0000\n",
            "Epoch 18/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 280258487353606144.0000\n",
            "Epoch 19/40\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 275512342333095936.0000\n",
            "Epoch 20/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 262799720173273088.0000\n",
            "Epoch 21/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 245949189081530368.0000\n",
            "Epoch 22/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 241246251432017920.0000\n",
            "Epoch 23/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 240179123857653760.0000\n",
            "Epoch 24/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 240309295726460928.0000\n",
            "Epoch 25/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 237406310151225344.0000\n",
            "Epoch 26/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 236890501758844928.0000\n",
            "Epoch 27/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 237576631374315520.0000\n",
            "Epoch 28/40\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 236030391608147968.0000\n",
            "Epoch 29/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 237016224041533440.0000\n",
            "Epoch 30/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 234916844027248640.0000\n",
            "Epoch 31/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 234163386504445952.0000\n",
            "Epoch 32/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 233806354463064064.0000\n",
            "Epoch 33/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 233338580984922112.0000\n",
            "Epoch 34/40\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 233823585871855616.0000\n",
            "Epoch 35/40\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 232274425527926784.0000\n",
            "Epoch 36/40\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 234062506312597504.0000\n",
            "Epoch 37/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 231079806144348160.0000\n",
            "Epoch 38/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 229217817562447872.0000\n",
            "Epoch 39/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 227111634319966208.0000\n",
            "Epoch 40/40\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 230313893216387072.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 246806103776559104.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 3s 12ms/step - loss: 338563407131181056.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 300483711688769536.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 299238171172929536.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 299181511964360704.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 298519468525486080.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 298282626848915456.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 297976137982672896.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 297298907539439616.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 297367386498007040.0000\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 297434284908609536.0000\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 296336491267751936.0000\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 296593605189959680.0000\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 296515642943602688.0000\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 295209801086926848.0000\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 293796035292037120.0000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 293610286546419712.0000\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 292738167667163136.0000\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 288895752485208064.0000\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 283711160023252992.0000\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 268969543773192192.0000\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 246084652350046208.0000\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 242223528290549760.0000\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 236839769605144576.0000\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 236631772928933888.0000\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 231379904099254272.0000\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 228402632769667072.0000\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 225274212950999040.0000\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 230650910710169600.0000\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 223209227034820608.0000\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 227684101920915456.0000\n",
            "Epoch 31/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 219965221056282624.0000\n",
            "Epoch 32/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 220332715637997568.0000\n",
            "Epoch 33/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 213567145714384896.0000\n",
            "Epoch 34/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 218014361011093504.0000\n",
            "Epoch 35/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 214838026537271296.0000\n",
            "Epoch 36/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 215021421640810496.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 254289964030754816.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 3s 20ms/step - loss: 322595886955757568.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 290448091104935936.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 290360164534452224.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 290054843899314176.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 288714058188718080.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 289182347062935552.0000\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 288514977864613888.0000\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 14ms/step - loss: 288526488376967168.0000\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 288090033800347648.0000\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 286775584829210624.0000\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 286483303714783232.0000\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 285092833822507008.0000\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 284263956673986560.0000\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 282032618084499456.0000\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 277101085095624704.0000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 264657997903429632.0000\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 245213942220062720.0000\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 240577164246777856.0000\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 236955235505930240.0000\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 239342636027084800.0000\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 236604834894053376.0000\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 239023434057646080.0000\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 236124004715331584.0000\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 1s 15ms/step - loss: 232140852045021184.0000\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 231550465840513024.0000\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 231507911304544256.0000\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 230421164319571968.0000\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 231319723017502720.0000\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 225684073090121728.0000\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 230190009179701248.0000\n",
            "Epoch 31/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 232814938572193792.0000\n",
            "Epoch 32/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 234109939931414528.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 243907894204956672.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 2s 12ms/step - loss: 315996686885322752.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 13ms/step - loss: 298708172208603136.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 299310979458531328.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 298987242003628032.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 298953328941858816.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 290157338998865920.0000\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 3s 20ms/step - loss: 309485138507464704.0000\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 289921253236539392.0000\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 289004707215572992.0000\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 289768386760540160.0000\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 16ms/step - loss: 289557830283821056.0000\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 289374555439366144.0000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 297839695461613568.0000\n",
            "Epoch 1/50\n",
            "133/133 [==============================] - 4s 13ms/step - loss: 310573448860532736.0000\n",
            "Epoch 2/50\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 293873344703365120.0000\n",
            "Epoch 3/50\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 293397393607491584.0000\n",
            "Epoch 4/50\n",
            "133/133 [==============================] - 3s 19ms/step - loss: 293783012951195648.0000\n",
            "Epoch 5/50\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 292829736369913856.0000\n",
            "Epoch 6/50\n",
            "133/133 [==============================] - 2s 11ms/step - loss: 291253998768357376.0000\n",
            "Epoch 7/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 291308424593932288.0000\n",
            "Epoch 8/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 287882191742959616.0000\n",
            "Epoch 9/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 282340292361715712.0000\n",
            "Epoch 10/50\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 262709903817179136.0000\n",
            "Epoch 11/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 245616346295959552.0000\n",
            "Epoch 12/50\n",
            "133/133 [==============================] - 2s 17ms/step - loss: 246619066540752896.0000\n",
            "Epoch 13/50\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 240199396103290880.0000\n",
            "Epoch 14/50\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 237302973238083584.0000\n",
            "Epoch 15/50\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 237003974794805248.0000\n",
            "Epoch 16/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 234097931202854912.0000\n",
            "Epoch 17/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 231852968977104896.0000\n",
            "Epoch 18/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 232873298587811840.0000\n",
            "Epoch 19/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 229023667860799488.0000\n",
            "Epoch 20/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 227289274167328768.0000\n",
            "Epoch 21/50\n",
            "133/133 [==============================] - 2s 13ms/step - loss: 226731495354531840.0000\n",
            "Epoch 22/50\n",
            "133/133 [==============================] - 3s 21ms/step - loss: 224643625852600320.0000\n",
            "Epoch 23/50\n",
            "133/133 [==============================] - 3s 20ms/step - loss: 220781282022391808.0000\n",
            "Epoch 24/50\n",
            "133/133 [==============================] - 2s 18ms/step - loss: 223481854378901504.0000\n",
            "Epoch 25/50\n",
            "133/133 [==============================] - 2s 14ms/step - loss: 220263343326232576.0000\n",
            "Epoch 26/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 221177260827213824.0000\n",
            "Epoch 27/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 221270788035051520.0000\n",
            "Epoch 28/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 216171510803464192.0000\n",
            "Epoch 29/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 218963325445210112.0000\n",
            "Epoch 30/50\n",
            "133/133 [==============================] - 2s 12ms/step - loss: 218028070546702336.0000\n",
            "Epoch 31/50\n",
            "133/133 [==============================] - 2s 15ms/step - loss: 220191565832781824.0000\n",
            "24/24 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "\n",
        "# Define the function to create the model (required for KerasRegressor)\n",
        "def create_model(input_shape, optimizer='adam'):\n",
        "    model = Sequential([\n",
        "        Dense(512, activation='relu', input_shape=input_shape),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Define the input shape based on the number of features\n",
        "input_shape = (X_train.shape[1],)\n",
        "\n",
        "\n",
        "# Define the hyperparameters grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'optimizer': ['adam', 'rmsprop'],\n",
        "    'batch_size': [32],\n",
        "    'epochs': [40, 50]\n",
        "}\n",
        "\n",
        "# Initialize a list to store the best models and their predictions\n",
        "best_models = []\n",
        "y_preds = []\n",
        "\n",
        "# Train and tune each model separately\n",
        "for label_index in range(y_train.shape[1]):\n",
        "    # Create a KerasRegressor model\n",
        "    keras_model = KerasRegressor(build_fn=create_model, input_shape=input_shape, verbose=1)\n",
        "\n",
        "    # Define early stopping callback.\n",
        "    early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Create a GridSearchCV instance for the current model\n",
        "    grid_search = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=2, verbose=1)\n",
        "\n",
        "    # Fit the GridSearchCV instance on the training data\n",
        "    grid_search.fit(X_train, y_train[:, label_index], callbacks=[early_stopping])\n",
        "\n",
        "    # Get the best parameters and best model from GridSearchCV\n",
        "    best_params = grid_search.best_params_\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Store the best model for evaluation\n",
        "    best_models.append(best_model)\n",
        "\n",
        "    # Make predictions using the best model\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    y_preds.append(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VDDZ-ghtDEXe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDDZ-ghtDEXe",
        "outputId": "8d450fd3-61af-43d3-f2a5-0e093d233afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 5ms/step\n",
            "24/24 [==============================] - 0s 6ms/step\n",
            "24/24 [==============================] - 0s 5ms/step\n",
            "24/24 [==============================] - 0s 4ms/step\n",
            "24/24 [==============================] - 0s 5ms/step\n",
            "[[9.7118266e+08 5.4260262e+08 1.6559528e+09 1.9600819e+08 9.2737264e+07]\n",
            " [9.5330720e+08 5.4333299e+08 1.6634614e+09 1.8435182e+08 9.4482800e+07]\n",
            " [6.3024742e+08 5.3582720e+08 1.6036188e+09 1.3884288e+08 8.8332440e+07]\n",
            " [3.2027044e+09 2.5366049e+09 1.8190922e+09 4.0258330e+08 2.0514381e+08]\n",
            " [4.2058639e+09 3.4461586e+09 1.9601068e+09 5.3829715e+08 2.5464581e+08]\n",
            " [4.2353178e+09 3.4733911e+09 1.9509555e+09 5.6229210e+08 2.5430858e+08]\n",
            " [1.8814226e+09 1.2983457e+09 1.7628791e+09 3.1254342e+08 1.2058366e+08]\n",
            " [2.1568594e+09 1.6982573e+09 1.7954980e+09 3.5639802e+08 1.2836869e+08]\n",
            " [2.3848691e+09 1.8995177e+09 1.8153078e+09 3.8874048e+08 1.3685462e+08]\n",
            " [3.3882772e+09 2.9110748e+09 1.8844677e+09 5.4362374e+08 2.0964627e+08]]\n",
            "(750, 5)\n"
          ]
        }
      ],
      "source": [
        "# Make predictions using the best models\n",
        "y_preds = np.column_stack([best_model.predict(X_test) for best_model in best_models])\n",
        "\n",
        "print(y_preds[:10, :10])\n",
        "print(y_preds.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GcRP_PjD-Y7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcRP_PjD-Y7b",
        "outputId": "f825d83d-a628-4ca9-a5e2-bebc0d0e527c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE:\n",
            "Mean: 961192128.0\n",
            "Median: 1102673024.0\n",
            "\n",
            "MSE:\n",
            "Mean: 5.149138846956388e+18\n",
            "Median: 4.434919733053096e+18\n",
            "\n",
            "RMSE:\n",
            "Mean: 1923678848.0\n",
            "Median: 2105924864.0\n",
            "\n",
            "R-squared (R2):\n",
            "Mean: 0.2694812297821045\n",
            "Median: 0.27633023262023926\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "rmse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Calculate evaluation metrics for each label using y_preds\n",
        "for idx in range(y_test.shape[1]):\n",
        "    # Calculate MAE\n",
        "    mae = mean_absolute_error(y_test[:, idx], y_preds[:, idx])\n",
        "    mae_scores.append(mae)\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse = mean_squared_error(y_test[:, idx], y_preds[:, idx])\n",
        "    mse_scores.append(mse)\n",
        "\n",
        "    # Calculate RMSE\n",
        "    rmse = np.sqrt(mse)\n",
        "    rmse_scores.append(rmse)\n",
        "\n",
        "    # Calculate R-squared (R2)\n",
        "    r2 = r2_score(y_test[:, idx], y_preds[:, idx])\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "\n",
        "# Convert the lists of metrics to numpy arrays for easier calculations\n",
        "mae_scores = np.array(mae_scores)\n",
        "mse_scores = np.array(mse_scores)\n",
        "rmse_scores = np.array(rmse_scores)\n",
        "r2_scores = np.array(r2_scores)\n",
        "\n",
        "# Calculate the mean or median of each metric across all labels\n",
        "final_metrics = {\n",
        "    'MAE': {\n",
        "        'Mean': np.mean(mae_scores),\n",
        "        'Median': np.median(mae_scores)\n",
        "    },\n",
        "    'MSE': {\n",
        "        'Mean': np.mean(mse_scores),\n",
        "        'Median': np.median(mse_scores)\n",
        "    },\n",
        "    'RMSE': {\n",
        "        'Mean': np.mean(rmse_scores),\n",
        "        'Median': np.median(rmse_scores)\n",
        "    },\n",
        "    'R-squared (R2)': {\n",
        "        'Mean': np.mean(r2_scores),\n",
        "        'Median': np.median(r2_scores)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Print the final aggregated metrics\n",
        "for metric_name, metric_values in final_metrics.items():\n",
        "    print(f\"{metric_name}:\")\n",
        "    print(f\"Mean: {metric_values['Mean']}\")\n",
        "    print(f\"Median: {metric_values['Median']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PjvdnFvD5MQo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjvdnFvD5MQo",
        "outputId": "f1acd666-190e-438d-e0a1-b64862262284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 most important features:\n",
            "Yearly Yield for Fruit Primary (Tonne/Hectare) : 0.23315754741966027\n",
            "Area_Brazil : 0.09460805967927605\n",
            "Year_numeric : 0.08066553825101229\n",
            "Country Total Land Area for Temporary Meadows and Pastures (Hectares) : 0.052886533054578244\n",
            "Area_Germany : 0.04114976174363495\n",
            "Area_Netherlands (Kingdom of the) : 0.04000134546756005\n",
            "Country Land Area Equipped for Irrigation (Hectares) : 0.0336591298793461\n",
            "Yearly Yield for Treenuts Total (Tonne/Hectare) : 0.03216871775925816\n",
            "Yearly Yield for Roots And Tubers Total (Tonne/Hectare) : 0.02962733156651818\n",
            "Yearly Yield for Vegetables Primary (Tonne/Hectare) : 0.02835806691307339\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load your data\n",
        "train_features = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/MLP Project/train_features.csv\")\n",
        "\n",
        "# Convert datetime column to numeric year\n",
        "train_features['Year'] = pd.to_datetime(train_features['Year'])\n",
        "train_features['Year_numeric'] = train_features['Year'].dt.year\n",
        "\n",
        "# Drop the original datetime column\n",
        "train_features.drop('Year', axis=1, inplace=True)\n",
        "\n",
        "# Extract feature names\n",
        "feature_names = train_features.columns.tolist()\n",
        "\n",
        "# Convert to numpy array for modeling\n",
        "X_train = np.asarray(train_features).astype(np.float32)\n",
        "\n",
        "# Initialize a list to store individual model feature importances\n",
        "feature_importances = []\n",
        "\n",
        "# Train and tune each model separately, and extract feature importances\n",
        "for label_index in range(y_train.shape[1]):\n",
        "    # Create a RandomForestRegressor model\n",
        "    rf_model = RandomForestRegressor(n_estimators=100)\n",
        "    rf_model.fit(X_train, y_train[:, label_index])\n",
        "\n",
        "    # Get feature importances and store them\n",
        "    feature_importances.append(rf_model.feature_importances_)\n",
        "\n",
        "# Aggregate feature importances across all models\n",
        "aggregate_importances = np.mean(feature_importances, axis=0)\n",
        "\n",
        "# Identify top N most important features\n",
        "top_n = 10\n",
        "top_feature_indices = np.argsort(aggregate_importances)[::-1][:top_n]\n",
        "top_feature_names = [feature_names[i] for i in top_feature_indices]\n",
        "\n",
        "print(\"Top\", top_n, \"most important features:\")\n",
        "for feature, importance in zip(top_feature_names, aggregate_importances[top_feature_indices]):\n",
        "    print(feature, \":\", importance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4uHMAx2xDP09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uHMAx2xDP09",
        "outputId": "0f8fc315-38d0-4590-d225-fc678ebc23de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Labels Shape: (750, 5)\n",
            "Predictions Shape: (750, 5)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the data\n",
        "train_features = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/MLP Project/train_features.csv\")\n",
        "train_labels = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/MLP Project/train_labels.csv\")\n",
        "test_features = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/MLP Project/test_features.csv\")\n",
        "test_labels = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/MLP Project/test_labels.csv\")\n",
        "\n",
        "# Add instance ID to test labels (true labels)\n",
        "test_labels['Instance ID'] = range(1, len(test_labels) + 1)\n",
        "\n",
        "# Define target columns\n",
        "target_columns = ['Export Value of Fruits and Vegetables (USD)',\n",
        "                  'Export Value of Non-food Items (USD)',\n",
        "                  'Export Value of Other food Items (USD)',\n",
        "                  'Export Value of Sugar and Honey Items (USD)',\n",
        "                  'Export Value of Tobacco (USD)']\n",
        "\n",
        "# Convert to numpy arrays\n",
        "y_test = np.asarray(test_labels[target_columns]).astype(np.float32)\n",
        "\n",
        "# Assuming y_preds is already defined with predictions\n",
        "\n",
        "# Add instance ID to predictions\n",
        "y_preds_with_id = np.column_stack([np.arange(1, len(y_preds) + 1), y_preds])\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "np.savetxt('model_predictions.csv', y_preds_with_id, delimiter=',', header='Instance ID,' + ','.join(target_columns), comments='')\n",
        "\n",
        "# Print the shapes of training and test data to verify\n",
        "print(\"Test Labels Shape:\", y_test.shape)\n",
        "print(\"Predictions Shape:\", y_preds.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a predicition API using FastAPT\n",
        "\n",
        "After the model has been created and predictions have been made, the next step is to build a prediction engine using FastApi to collect user input and make future predictions bases on the user input."
      ],
      "metadata": {
        "id": "_vD2uIUIKl6E"
      },
      "id": "_vD2uIUIKl6E"
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save each trained model for different target columns\n",
        "target_columns = [\n",
        "    'Export Value of Fruits and Vegetables (USD)',\n",
        "    'Export Value of Non-food Items (USD)',\n",
        "    'Export Value of Other food Items (USD)',\n",
        "    'Export Value of Sugar and Honey Items (USD)',\n",
        "    'Export Value of Tobacco (USD)'\n",
        "]\n",
        "\n",
        "model_paths = [\n",
        "    \"model_fruits_vegetables.joblib\",\n",
        "    \"model_non_food_items.joblib\",\n",
        "    \"model_other_food_items.joblib\",\n",
        "    \"model_sugar_honey.joblib\",\n",
        "    \"model_tobacco.joblib\"\n",
        "]\n",
        "\n",
        "# Save each model using joblib\n",
        "for model, path in zip(best_models, model_paths):\n",
        "    joblib.dump(model, path)\n"
      ],
      "metadata": {
        "id": "wv8hBIJTW2HS"
      },
      "id": "wv8hBIJTW2HS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import joblib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Initialize FastAPI\n",
        "app = FastAPI()\n",
        "\n",
        "# Load saved models for each target\n",
        "model_paths = [\n",
        "    \"model_fruits_vegetables.joblib\",\n",
        "    \"model_non_food_items.joblib\",\n",
        "    \"model_other_food_items.joblib\",\n",
        "    \"model_sugar_honey.joblib\",\n",
        "    \"model_tobacco.joblib\"\n",
        "]\n",
        "models = [joblib.load(path) for path in model_paths]\n",
        "\n",
        "# Define available country names for one-hot encoding\n",
        "country_names = [\n",
        "    'Afghanistan', 'Albania', 'Algeria', 'American Samoa', 'Andorra', 'Angola', 'Anguilla',\n",
        "    'Antarctica', 'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba', 'Australia',\n",
        "    'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus',\n",
        "    # Add all countries here for one-hot encoding...\n",
        "]\n",
        "\n",
        "# Define the input data model\n",
        "class PredictionInput(BaseModel):\n",
        "    year: int\n",
        "    standard_dev_temp_dec_jan_feb: float\n",
        "    standard_dev_temp_jun_jul_aug: float\n",
        "    standard_dev_temp_mar_apr_may: float\n",
        "    standard_dev_temp_meteorological_year: float\n",
        "    standard_dev_temp_sept_oct_nov: float\n",
        "    change_temp_dec_jan_feb: float\n",
        "    change_temp_jun_jul_aug: float\n",
        "    change_temp_mar_apr_may: float\n",
        "    change_temp_meteorological_year: float\n",
        "    change_temp_sept_oct_nov: float\n",
        "    avg_exchange_rate: float\n",
        "    yield_cereals_primary: float\n",
        "    yield_citrus_fruit_total: float\n",
        "    yield_fibre_crops: float\n",
        "    yield_fruit_primary: float\n",
        "    yield_oilcrops_cake_equivalent: float\n",
        "    yield_oilcrops_oil_equivalent: float\n",
        "    yield_pulses_total: float\n",
        "    yield_roots_tubers_total: float\n",
        "    yield_sugar_crops_primary: float\n",
        "    yield_treenuts_total: float\n",
        "    yield_vegetables_primary: float\n",
        "    agri_land_mass: float\n",
        "    land_mass_agriculture: float\n",
        "    arable_land_mass: float\n",
        "    area_land_mass: float\n",
        "    cropland_mass: float\n",
        "    land_area: float\n",
        "    land_area_irrigation: float\n",
        "    permanent_crops_area: float\n",
        "    meadows_pastures_total_area: float\n",
        "    total_area_temporary_crops: float\n",
        "    total_area_temporary_fallow: float\n",
        "    total_area_temporary_meadows: float\n",
        "    country: str  # Add a 'country' field to accept country input\n",
        "\n",
        "# Prediction endpoint\n",
        "@app.post(\"/predict\")\n",
        "async def predict(data: PredictionInput):\n",
        "    # Convert input data into an array format that matches model input\n",
        "    input_data = [\n",
        "        data.year, data.standard_dev_temp_dec_jan_feb, data.standard_dev_temp_jun_jul_aug,\n",
        "        data.standard_dev_temp_mar_apr_may, data.standard_dev_temp_meteorological_year,\n",
        "        data.standard_dev_temp_sept_oct_nov, data.change_temp_dec_jan_feb, data.change_temp_jun_jul_aug,\n",
        "        data.change_temp_mar_apr_may, data.change_temp_meteorological_year, data.change_temp_sept_oct_nov,\n",
        "        data.avg_exchange_rate, data.yield_cereals_primary, data.yield_citrus_fruit_total,\n",
        "        data.yield_fibre_crops, data.yield_fruit_primary, data.yield_oilcrops_cake_equivalent,\n",
        "        data.yield_oilcrops_oil_equivalent, data.yield_pulses_total, data.yield_roots_tubers_total,\n",
        "        data.yield_sugar_crops_primary, data.yield_treenuts_total, data.yield_vegetables_primary,\n",
        "        data.agri_land_mass, data.land_mass_agriculture, data.arable_land_mass, data.area_land_mass,\n",
        "        data.cropland_mass, data.land_area, data.land_area_irrigation, data.permanent_crops_area,\n",
        "        data.meadows_pastures_total_area, data.total_area_temporary_crops,\n",
        "        data.total_area_temporary_fallow, data.total_area_temporary_meadows\n",
        "    ]\n",
        "\n",
        "    # Create one-hot encoding array for countries\n",
        "    one_hot_countries = [1 if country == data.country else 0 for country in country_names]\n",
        "\n",
        "    # Append one-hot encoded country data to the input features\n",
        "    input_data.extend(one_hot_countries)\n",
        "    input_data = np.array([input_data])\n",
        "\n",
        "    # Placeholder to store predictions for each target label\n",
        "    predictions = []\n",
        "\n",
        "    # Generate predictions for each label for the next 3 years\n",
        "    for model in models:\n",
        "        yearly_predictions = []\n",
        "        for year_ahead in range(1, 4):  # Predict for the next 1, 2, and 3 years\n",
        "            input_data[0][0] = data.year + year_ahead  # Update year in the input data\n",
        "            yearly_predictions.append(model.predict(input_data)[0])\n",
        "        predictions.append(yearly_predictions)\n",
        "\n",
        "    # Structure the response with predictions for each target label\n",
        "    target_labels = [\n",
        "        \"Export Value of Fruits and Vegetables (USD)\",\n",
        "        \"Export Value of Non-food Items (USD)\",\n",
        "        \"Export Value of Other food Items (USD)\",\n",
        "        \"Export Value of Sugar and Honey Items (USD)\",\n",
        "        \"Export Value of Tobacco (USD)\"\n",
        "    ]\n",
        "\n",
        "    # Construct the final output in a structured format\n",
        "    response = {\n",
        "        target_labels[i]: {\n",
        "            \"1_year_ahead\": predictions[i][0],\n",
        "            \"2_years_ahead\": predictions[i][1],\n",
        "            \"3_years_ahead\": predictions[i][2]\n",
        "        } for i in range(len(target_labels))\n",
        "    }\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "viyR1URBLPOb"
      },
      "id": "viyR1URBLPOb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "vRd_NB3Q9wIn",
      "metadata": {
        "id": "vRd_NB3Q9wIn"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "### Feature Importance\n",
        "\n",
        "The important features that were indispensable for the model to perform well on the data was\n",
        "gotten using randomforestregressor models. These were the features and their weighted\n",
        "contributions to model performance;\n",
        "- Yearly Yield for Fruit Primary (Tonne/Hectare) : 0.238\n",
        "- Area_Brazil : 0.093\n",
        "- Year_numeric : 0.078\n",
        "- Country Total Land Area for Temporary Meadows and Pastures (Hectares) : 0.055\n",
        "- Area_Germany : 0.042\n",
        "- Area_Netherlands (Kingdom of the) : 0.038\n",
        "- Country Land Area Equipped for Irrigation (Hectares) : 0.032\n",
        "- Yearly Yield for Treenuts Total (Tonne/Hectare) : 0.032\n",
        "- Yearly Yield for Roots And Tubers Total (Tonne/Hectare) : 0.029\n",
        "- Yearly Yield for Vegetables Primary (Tonne/Hectare) : 0.027\n",
        "\n",
        "The top 10 most important features, as determined by feature importance scores, provide valuable insights into the factors driving the model's predictions for export values of agricultural products. Yearly Yield for Fruit Primary (Tonne/Hectare) emerges as the most critical feature, indicating that the production yield of primary fruits per hectare significantly influences export values.\n",
        "\n",
        "Other important features include specific geographical areas such as Brazil and Germany, along with agricultural yield metrics for various crops.\n",
        "\n",
        "### Conclusion and Recommendation\n",
        "\n",
        "Due to these metrics gotten:\n",
        "- MAE: 919240192.0, MSE: 4.631e+18,\n",
        "- RMSE: 1852330240.0 and\n",
        "- R-squared (R2): 0.309, we can see that the model's performance is not ideal, as indicated by the relatively high errors (MAE, MSE, RMSE) and the moderate R-squared score value. While it can capture some patterns in the data, it struggles to make accurate predictions consistently. Some further approach\n",
        "that can be taken to improve the model’s performance includes;\n",
        "- Getting more robust, consistent and informative data. Due to the fact that the values across the different data files were not consistent, only data values between year 2000 and 2019 were able to be considered. This lead to loss of valuable data. Also even after selecting data across only 19 years, there were still numerous missing data which had to\n",
        "be imputed. The large amount of imputed data (especially in the target columns) can greatly affect the time-series quality of the data.  More informative features, addition of more informative features and datasets to the\n",
        "dataset files would also greatly improve the ability of the neural networks model to learn patterns from the data.  More time: Due to the time deadline nature of the project, enough robust training\n",
        "methodologies and tuning algorithms were not able to be implemented. With more time and more in-depth training and tuning strategies, the performance of the models in capturing patterns from the dataset would improve.  Domain Knowledge\n",
        "\n",
        "Integration: Consulting a domain expert on international exports can also give more insights into how best feature engineering can be done to improve model scores on the data. By implementing these strategies, the model can be refined to better capture the underlying patterns and dynamics in agricultural export values, ultimately leading to improved performance and more accurate predictions in future tests and real-world application"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yulN6c-sMtHD"
      },
      "id": "yulN6c-sMtHD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}